{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaSBweZwUuOk"
   },
   "source": [
    "# ğŸ¤– AI, CA3, Machine Learning ğŸ“š  \n",
    "\n",
    "* **Name** : Mohammad Sadra ğŸ–Š  \n",
    "* **Last Name** :  Abbasi ğŸ“  \n",
    "* **SID** : 810101469 ğŸ†”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du8DTCJYUuOr"
   },
   "source": [
    "# IMPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class Preprocessor:\n",
    "    def __init__(self, target_col='crisis_type', numerical_strategy='mean', categorical_strategy='most_frequent'):\n",
    "        self.target_col = target_col\n",
    "        self.num_strategy = numerical_strategy\n",
    "        self.cat_strategy = categorical_strategy\n",
    "        \n",
    "        self.num_imputer = None\n",
    "        self.cat_imputer = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.target_encoder = LabelEncoder()\n",
    "        \n",
    "        self.num_cols = []\n",
    "        self.cat_cols = []\n",
    "        self.outlier_bounds = {}\n",
    "\n",
    "    def _feature_engineering(self, df):\n",
    "        df_copy = df.copy()\n",
    "                    \n",
    "        if 'avg_sleep_last_week' in df_copy.columns and 'sleep_hours_before_exam' in df_copy.columns:\n",
    "            df_copy['sleep_stability'] = abs(df_copy['avg_sleep_last_week'] - df_copy['sleep_hours_before_exam'])\n",
    "            \n",
    "        return df_copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = self._feature_engineering(X)\n",
    "        \n",
    "        self.num_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        self.cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        if self.target_col in self.cat_cols: self.cat_cols.remove(self.target_col)\n",
    "        \n",
    "        self.num_imputer = SimpleImputer(strategy=self.num_strategy)\n",
    "        self.num_imputer.fit(X[self.num_cols])\n",
    "        \n",
    "        self.cat_imputer = SimpleImputer(strategy=self.cat_strategy)\n",
    "        self.cat_imputer.fit(X[self.cat_cols])\n",
    "        \n",
    "        for col in self.num_cols:\n",
    "            Q1 = X[col].quantile(0.01)\n",
    "            Q3 = X[col].quantile(0.99)\n",
    "            self.outlier_bounds[col] = (Q1, Q3)\n",
    "\n",
    "        for col in self.cat_cols:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "            \n",
    "        if y is not None:\n",
    "            self.target_encoder.fit(y)\n",
    "            \n",
    "        X_temp_num = self.num_imputer.transform(X[self.num_cols])\n",
    "        self.scaler.fit(X_temp_num)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        \n",
    "        X = self._feature_engineering(X)\n",
    "        \n",
    "        X[self.num_cols] = self.num_imputer.transform(X[self.num_cols])\n",
    "        X[self.cat_cols] = self.cat_imputer.transform(X[self.cat_cols])\n",
    "        \n",
    "        for col in self.num_cols:\n",
    "            lower, upper = self.outlier_bounds[col]\n",
    "            X[col] = np.clip(X[col], lower, upper)\n",
    "            \n",
    "        for col in self.cat_cols:\n",
    "            le = self.label_encoders[col]\n",
    "            X[col] = X[col].astype(str).map(lambda s: s if s in le.classes_ else le.classes_[0])\n",
    "            X[col] = le.transform(X[col])\n",
    "            \n",
    "        X[self.num_cols] = self.scaler.transform(X[self.num_cols].values)\n",
    "        \n",
    "        y_transformed = None\n",
    "        if y is not None:\n",
    "            y_transformed = self.target_encoder.transform(y)\n",
    "            \n",
    "        if y is not None:\n",
    "            return X, y_transformed\n",
    "        else:\n",
    "            return X\n",
    "        \n",
    "    def plot_correlation(self, X, y=None):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        df_temp = pd.DataFrame(X, columns=self.num_cols + self.cat_cols)\n",
    "        \n",
    "        if y is not None:\n",
    "            df_temp[self.target_col] = y\n",
    "            \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(df_temp.corr(), annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "        plt.title(\"Feature Correlation Matrix\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv('./part3_dataset/part3_dataset.csv')\n",
    "\n",
    "X_raw = data.drop('crisis_type', axis=1)\n",
    "y_raw = data['crisis_type']\n",
    "\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(X_raw, y_raw, test_size=0.3, random_state=42)\n",
    "\n",
    "preprocessor = Preprocessor(target_col='crisis_type')\n",
    "preprocessor.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "X_train, y_train = preprocessor.transform(X_train_raw, y_train_raw)\n",
    "X_val, y_val = preprocessor.transform(X_val_raw, y_val_raw)\n",
    "\n",
    "# preprocessor.plot_correlation(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.8;\">\n",
    "    <h3 style=\"margin-top: 15px;\">ØªÙˆØ¶ÛŒØ­Ø§Øª</h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø§Ø² Ù…Ø¯Ù„ Ù‡Ø§ÛŒ Ø¯Ø±Ø®ØªÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ú©Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ùˆ Ø¨Ø±Ø´ Ø²Ø¯Ù† Ø¯Ø§Ø¯Ù‡ Ù‡Ø§ Ú©Ø§Ø± Ù…ÛŒ Ú©Ù†Ù†Ø¯ Ø¨Ù†Ø§Ø¨Ø±Ø§ÛŒÙ† Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ scale Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ ØµØ­ÛŒØ­ Ø¢Ù†Ù‡Ø§ Ù†ÛŒØ³Øª Ù‡Ø±Ú†Ù†Ø¯ Ø¯Ø± Ø§ÛŒÙ† Ú©Ø¯ Ø§Ø¶Ø§ÙÙ‡ Ø´Ø¯Ù‡ ØªØ§ Ø¨Ù‡ ØµÙˆØ±Øª Ø¹Ù…ÙˆÙ…ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„ Ù‡Ø§ÛŒ Ø®Ø·ÛŒ Ù‡Ù… Ø¨ØªÙˆØ§Ù†Ø¯ Ù…ÙˆØ±Ø¯ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù‚Ø±Ø§Ø± Ø¨Ú¯ÛŒØ±Ø¯\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙ†ÛŒ Ø¨Ù‡ Ø¹Ø¯Ø¯ÛŒ Ø§Ø² Ø±ÙˆØ´ Label Encoding Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ú©Ù‡ Ø¯Ø± Ø¢Ù† Ø¨Ù‡ Ù‡Ø± Ù…Ù‚Ø¯Ø§Ø± ÛŒÙˆÙ†ÛŒÚ© Ù…ÙˆØ¬ÙˆØ¯ Ø¯Ø± Ù‡Ø± Ø³ØªÙˆÙ† ÛŒÚ© Ø¹Ø¯Ø¯ Ù†Ø³Ø¨Øª Ø¯Ø§Ø¯Ù‡ Ù…ÛŒ Ø´ÙˆØ¯ Ø¹Ù„Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§ÛŒÙ† Ø§Ø³Øª Ú©Ù‡ Ø¯Ø± Ù…Ø¯Ù„ Ù‡Ø§ÛŒ Ø¯Ø±Ø®ØªÛŒ Ø§ÛŒØ¬Ø§Ø¯ ØªØ±ØªÛŒØ¨ Ù…ØµÙ†ÙˆØ¹ÛŒ Ø¯Ø± Ø³ØªÙˆÙ† Ù‡Ø§ÛŒ Ù…ØªÙ†ÛŒ Ø¨Ø§Ø¹Ø« Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù†Ø§Ø¯Ø±Ø³Øª Ø¢Ù† Ù†Ù…ÛŒ Ø´ÙˆØ¯ Ø²ÛŒØ±Ø§ Ø§ÛŒÙ† Ù…Ø¯Ù„ Ù‡Ø§ ØµØ±ÙØ§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ú©Ø§Ø± Ù…ÛŒ Ú©Ù†Ù†Ø¯ Ùˆ Ø¨Ù‡ Ø¯Ù†Ø¨Ø§Ù„ Ù†Ù‚Ø·Ù‡ Ø¨Ø±Ø´ Ø¨Ù‡ÛŒÙ†Ù‡ Ù‡Ø³ØªÙ†Ø¯ Ø¨Ù†Ø§Ø¨Ø± Ø§ÛŒÙ† Ù†ÛŒØ§Ø²ÛŒ Ø¨Ù‡ Ø§ÙØ²Ø§ÛŒØ´ Ø§Ø¨Ø¹Ø§Ø¯ Ø¬Ø¯ÙˆÙ„ Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ one hot Ù†Ø¨ÙˆØ¯\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/correlation_matrix_part3.png\" width=\"800\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.8;\">\n",
    "    <h3 style=\"margin-top: 15px;\">ØªÙØ³ÛŒØ± Ù…Ø§ØªØ±ÛŒØ³ correlation</h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "Ø¯Ø± Ù…Ø¬Ù…ÙˆØ¹ØŒ Ø±ÙˆØ§Ø¨Ø· Ù…Ø´Ø§Ù‡Ø¯Ù‡â€ŒØ´Ø¯Ù‡ Ø¨ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ù…Ù†Ø·Ù‚ÛŒ Ø¨Ù‡ Ù†Ø¸Ø± Ù…ÛŒâ€ŒØ±Ø³Ù†Ø¯. Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ø³ÛŒØ§Ø± Ø¨Ø§Ù„Ø§ÛŒ Ø¨ÛŒÙ† Ø¯Ùˆ ÙˆÛŒÚ˜Ú¯ÛŒ <em>num_assignments_done</em> Ùˆ <em>assignments_done_ratio</em> Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø§ÛŒÙ† Ø¯Ùˆ Ù…ØªØºÛŒØ± ØªØ§ Ø­Ø¯ Ø²ÛŒØ§Ø¯ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª ØªÚ©Ø±Ø§Ø±ÛŒ Ø¯Ø± Ø§Ø®ØªÛŒØ§Ø± Ù…Ø¯Ù„ Ù‚Ø±Ø§Ø± Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ Ùˆ Ø¯Ø± ØµÙˆØ±Øª Ù†ÛŒØ§Ø² Ù…ÛŒâ€ŒØªÙˆØ§Ù† ÛŒÚ©ÛŒ Ø§Ø² Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ø¯ÙˆÙ† Ø§Ø² Ø¯Ø³Øª Ø±ÙØªÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø¹Ù†Ø§Ø¯Ø§Ø± Ø­Ø°Ù Ú©Ø±Ø¯. Ø§Ø² Ø·Ø±Ù Ø¯ÛŒÚ¯Ø±ØŒ Ù¾Ø§ÛŒÛŒÙ† Ø¨ÙˆØ¯Ù† Ù…Ù‚Ø§Ø¯ÛŒØ± Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ù¾ÛŒØ±Ø³ÙˆÙ† Ø¨ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ù„Ø²ÙˆÙ…Ø§ Ø¨Ù‡ Ù…Ø¹Ù†Ø§ÛŒ Ø¶Ø¹ÛŒÙ ÛŒØ§ Ø¨ÛŒâ€ŒØ§Ù‡Ù…ÛŒØª Ø¨ÙˆØ¯Ù† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ù†ÛŒØ³Øª. Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ Ø¨ÛŒØ´ØªØ± Ø¨Ù‡ ØºÛŒØ±Ø®Ø·ÛŒ Ø¨ÙˆØ¯Ù† Ø±ÙˆØ§Ø¨Ø· Ø¨ÛŒÙ† Ù…ØªØºÛŒØ±Ù‡Ø§ Ùˆ Ù†Ø­ÙˆÙ‡ Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ø¨Ø±Ú†Ø³Ø¨ Ù‡Ø¯Ù Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Label Encoding Ø¨Ø§Ø²Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯ØŒ Ú©Ù‡ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø±Ø§Ø¨Ø·Ù‡ ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø®Ø·ÛŒ Ù‚Ø§Ø¨Ù„ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù†Ø¨Ø§Ø´Ø¯. Ø¯Ø± Ú†Ù†ÛŒÙ† Ø´Ø±Ø§ÛŒØ·ÛŒØŒ Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ù…Ø§Ù†Ù†Ø¯ Ù‡Ù…Ø¨Ø³ØªÚ¯ÛŒ Ø®Ø·ÛŒ ØªÙˆØ§Ù† Ù†Ù…Ø§ÛŒØ´ ØªØ¹Ø§Ù…Ù„Ø§Øª Ù¾ÛŒÚ†ÛŒØ¯Ù‡ Ø¨ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ù†Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø¯Ù„ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ ØºÛŒØ±Ø®Ø·ÛŒ Ù…Ø§Ù†Ù†Ø¯ Decision Tree Ùˆ Random Forest Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ Ø§Ù†ØªØ®Ø§Ø¨ Ù…Ù†Ø§Ø³Ø¨ÛŒ Ù…Ø­Ø³ÙˆØ¨ Ù…ÛŒâ€ŒØ´ÙˆØ¯ØŒ Ø²ÛŒØ±Ø§ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù‚Ø§Ø¯Ø±Ù†Ø¯ Ø±ÙˆØ§Ø¨Ø· Ø´Ø±Ø·ÛŒ Ùˆ ØºÛŒØ±Ø®Ø·ÛŒ Ø¨ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ Ùˆ Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ø±Ø§ Ø¨Ù‡ØªØ± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ú©Ù†Ù†Ø¯.\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Training and Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=4, random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_val)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Overall Accuracy: {acc:.4f}\")\n",
    "\n",
    "report = classification_report(y_val, y_pred, target_names=preprocessor.target_encoder.classes_, output_dict=True)\n",
    "print(f\"Macro Precision: {report['macro avg']['precision']:.4f}\")\n",
    "print(f\"Macro Recall:    {report['macro avg']['recall']:.4f}\")\n",
    "print(f\"Macro F1-Score:  {report['macro avg']['f1-score']:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=preprocessor.target_encoder.classes_,\n",
    "            yticklabels=preprocessor.target_encoder.classes_)\n",
    "plt.title(\"Confusion Matrix - Decision Tree\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt_model, \n",
    "          feature_names=preprocessor.num_cols + preprocessor.cat_cols, \n",
    "          class_names=preprocessor.target_encoder.classes_, \n",
    "          filled=True, fontsize=10)\n",
    "plt.title(\"Decision Tree Visualization\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.8;\">\n",
    "    <h3 style=\"margin-top: 15px;\">ØªÙˆØ¶ÛŒØ­Ø§Øª</h3>\n",
    "</div>\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/3class_res_part3.png \" width=\"800\"></td>\n",
    "        <td><img src=\"./Assets/3class_tree_part3.png\" width=\"800\"></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>overall results</td>\n",
    "        <td>tree</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "Û±. ØªÙØ§ÙˆØª Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§: Ø¯Ø± Ø­Ø§Ù„Øª Ú†Ù†Ø¯Ú©Ù„Ø§Ø³Ù‡ Ø§Ø² Ø±ÙˆØ´ Macro-Averaging Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ø¯Ø± Ø§ÛŒÙ† Ø±ÙˆØ´ØŒ Ø§Ø¨ØªØ¯Ø§ Ù…Ø³Ø¦Ù„Ù‡ Ø¨Ù‡ Ú†Ù†Ø¯ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡â€ŒÛŒ Ø¨Ø§ÛŒÙ†Ø±ÛŒ (One-vs-Rest) Ø´Ú©Ø³ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ Ù…ØªØ±ÛŒÚ©â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ù†Ø¯. Ø³Ù¾Ø³ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø­Ø³Ø§Ø¨ÛŒ (Ø¨Ø¯ÙˆÙ† ÙˆØ²Ù†â€ŒØ¯Ù‡ÛŒ) Ø¢Ù†â€ŒÙ‡Ø§ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ ØªØ§ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ù…Ø¯Ù„ Ø±ÙˆÛŒ ØªÙ…Ø§Ù… Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ù‡Ù…ÛŒØª ÛŒÚ©Ø³Ø§Ù† Ø³Ù†Ø¬ÛŒØ¯Ù‡ Ø´ÙˆØ¯.\n",
    "\n",
    "Û². Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§: Ø·Ø¨Ù‚ Ø¢Ù†ØªØ±ÙˆÙ¾ÛŒ/Ø¬ÛŒÙ†ÛŒ Ø¯Ø± Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ…ØŒ ÙˆÛŒÚ˜Ú¯ÛŒ stress_level Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø§Ù‡Ù…ÛŒØª Ø±Ø§ Ø¯Ø± Ø¬Ø¯Ø§Ø³Ø§Ø²ÛŒ Ú¯Ø±Ù‡â€ŒÙ‡Ø§ Ø¯Ø§Ø´ØªÙ‡ Ø§Ø³Øª Ùˆ Ù¾Ø³ Ø§Ø² Ø¢Ù† num_assignments_done Ùˆ sleep_hours_before_exam Ù‚Ø±Ø§Ø± Ø¯Ø§Ø±Ù†Ø¯. Ø§ÛŒÙ† Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ ÙˆØ¶Ø¹ÛŒØª Ø±ÙˆØ§Ù†ÛŒ Ùˆ Ø®ÙˆØ§Ø¨ Ø¯Ø§Ù†Ø´Ø¬Ùˆ Ù…Ù‡Ù…â€ŒØªØ±ÛŒÙ† Ø´Ø§Ø®Øµâ€ŒÙ‡Ø§ÛŒ Ø¨Ø­Ø±Ø§Ù† Ù‡Ø³ØªÙ†Ø¯.\n",
    "\n",
    "Û³. ØªØ­Ù„ÛŒÙ„ Ø®Ø·Ø§: Ø¨Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø§ØªØ±ÛŒØ³ Ø¯Ø±Ù‡Ù…â€ŒØ±ÛŒØ®ØªÚ¯ÛŒ (Confusion Matrix)ØŒ Ø¨ÛŒØ´ØªØ±ÛŒÙ† Ø®Ø·Ø§ÛŒ Ù…Ø¯Ù„ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ú©Ù„Ø§Ø³ Denial_mode Ø§Ø³Øª Ú©Ù‡ Ø§Ø´ØªØ¨Ø§Ù‡Ø§Ù‹ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† No_issue Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¯Ù„ÛŒÙ„ Ø§ÛŒÙ† Ø§Ù…Ø± Ø´Ø¨Ø§Ù‡Øª Ø§Ù„Ú¯ÙˆÛŒ Ø±ÙØªØ§Ø±ÛŒ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒØ§Ù† Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ú©Ø§Ø± Ø¨Ø§ Ø¯Ø§Ù†Ø´Ø¬ÙˆÛŒØ§Ù† Ø¨Ø¯ÙˆÙ† Ù…Ø´Ú©Ù„ Ø§Ø³Øª.\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "rf_base = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],        # number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],            # maximum depth of each tree\n",
    "    'min_samples_split': [2, 5, 10],            # minimum samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],              # minimum samples required at each leaf node\n",
    "    'bootstrap': [True, False]                  # bootstrap sampling method true means sampling with replacement and false means without replacement\n",
    "}\n",
    "\n",
    "rf_search = RandomizedSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_distributions=rf_param_grid,\n",
    "    n_iter=20,\n",
    "    cv=3,                 # number of cross-validation splits\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1             # use all available cores\n",
    ")\n",
    "\n",
    "rf_search.fit(X_train, y_train)\n",
    "best_rf_model = rf_search.best_estimator_\n",
    "\n",
    "y_rf_pred = best_rf_model.predict(X_val)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_rf_pred):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_rf_pred))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion_matrix(y_val, y_rf_pred), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title(\"Confusion Matrix - Tuned Random Forest\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/bagging_model_res.png\" width=\"600\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "gb_base = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [50, 100],      # number of trees in the forest   \n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # learning rate\n",
    "    'max_depth': [3, 5]               # maximum depth of each tree\n",
    "}\n",
    "\n",
    "gb_search = GridSearchCV(\n",
    "    estimator=gb_base,\n",
    "    param_grid=gb_param_grid,\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "gb_search.fit(X_train, y_train)\n",
    "\n",
    "best_gb_model = gb_search.best_estimator_\n",
    "y_pred_gb = best_gb_model.predict(X_val)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_val, y_pred_gb):.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_val, y_pred_gb))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(confusion_matrix(y_val, y_pred_gb), annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title(\"Confusion Matrix - Tuned Gradient Boosting\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/boosting_model_result.png\" width=\"600\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø³ÙˆØ§Ù„Ø§Øª\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "Ø±ÙˆØ´ One-Hot Encoding Ø¨Ù‡ Ø·ÙˆØ± Ú©Ù„ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø·ÛŒ Ù…Ù†Ø§Ø³Ø¨â€ŒØªØ± Ø§Ø³ØªØŒ Ø²ÛŒØ±Ø§ Ø¯Ø± Label Encoding Ø¨Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙ†ÛŒ Ú©Ù‡ Ø°Ø§ØªØ§ Ù‡ÛŒÚ†â€ŒÚ¯ÙˆÙ†Ù‡ Ø¨Ø±ØªØ±ÛŒ ÛŒØ§ ØªØ±ØªÛŒØ¨ Ù…Ø¹Ù†Ø§ÛŒÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ ÛŒÚ©Ø¯ÛŒÚ¯Ø± Ù†Ø¯Ø§Ø±Ù†Ø¯ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø¶Ù…Ù†ÛŒ ÛŒÚ© ØªØ±ØªÛŒØ¨ Ø¹Ø¯Ø¯ÛŒ Ù†Ø³Ø¨Øª Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø§ÛŒÙ† Ù…ÙˆØ¶ÙˆØ¹ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¯Ø±Ø®ØªÛŒ Ù…Ø¹Ù…ÙˆÙ„Ø§ Ù…Ø´Ú©Ù„â€ŒØ³Ø§Ø² Ù†ÛŒØ³ØªØŒ Ú†Ø±Ø§ Ú©Ù‡ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ùˆ ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ Ø¨Ù‡ ÙØ§ØµÙ„Ù‡ Ø¹Ø¯Ø¯ÛŒ Ø¨ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± ØªÙˆØ¬Ù‡ÛŒ Ù†Ø¯Ø§Ø±Ù†Ø¯. Ø§Ù…Ø§ Ø¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø®Ø·ÛŒØŒ Ø§ÛŒÙ† Ù…Ø³Ø¦Ù„Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ø§Ø¹Ø« Ø¨Ø±ÙˆØ² Ø®Ø·Ø§ Ø´ÙˆØ¯ØŒ Ø²ÛŒØ±Ø§ Ø§ÛŒÙ† Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¹Ø¯Ø¯ÛŒ Ø±Ø§ Ù…Ø³ØªÙ‚ÛŒÙ…Ø§ Ø¯Ø± Ø±ÙˆØ§Ø¨Ø· Ø±ÛŒØ§Ø¶ÛŒ Ø®ÙˆØ¯ ÙˆØ§Ø±Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ Ø¨Ù‡ Ø¨Ø±Ú†Ø³Ø¨ÛŒ Ú©Ù‡ Ø¹Ø¯Ø¯ Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒ Ø¨Ù‡ Ø¢Ù† Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ØŒ ÙˆØ²Ù† Ùˆ Ø§Ù‡Ù…ÛŒØª Ø¨ÛŒØ´ØªØ±ÛŒ Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯. Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ø¯Ø± ÙˆØ§Ù‚Ø¹ÛŒØªØŒ ØªÙ…Ø§Ù…ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù…ØªÙ†ÛŒ Ø§Ø² Ø§Ù‡Ù…ÛŒØª ÛŒÚ©Ø³Ø§Ù†ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ù‡Ø³ØªÙ†Ø¯ Ùˆ Ù‡ÛŒÚ† ØªØ±ØªÛŒØ¨ Ø°Ø§ØªÛŒ Ø¨ÛŒÙ† Ø¢Ù†â€ŒÙ‡Ø§ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-vs-Rest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = preprocessor.target_encoder.classes_ \n",
    "models = {}\n",
    "\n",
    "for class_idx, class_label in enumerate(class_names):\n",
    "    y_train_binary = (y_train == class_idx).astype(int)\n",
    "    \n",
    "    dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "    dt.fit(X_train, y_train_binary)\n",
    "    \n",
    "    models[class_idx] = dt\n",
    "\n",
    "probilities = np.zeros((len(X_val), 3))\n",
    "\n",
    "for class_idx, class_label in enumerate(class_names):\n",
    "    probilities[:, class_idx] = models[class_idx].predict_proba(X_val)[:, 1]\n",
    "\n",
    "y_pred = np.argmax(probilities, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_val, y_pred)\n",
    "print(f\"Overall Accuracy: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred, target_names=class_names))\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "cm = confusion_matrix(y_val, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', \n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix - One vs Rest Strategy\")\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/One-vs-Rest_res.png\" width=\"600\"></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ø³ÙˆØ§Ù„Ø§Øª\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "ÙˆÙ‚ØªÛŒ Ø§Ø² Label Encoding Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ø¨Ù‡ Ù‡Ø± Ú©Ù„Ø§Ø³ ÛŒÚ© Ø¹Ø¯Ø¯ Ø§Ø®ØªØµØ§Øµ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ø§ÛŒÙ† Ø§Ø¹Ø¯Ø§Ø¯ ÙÙ‚Ø· Ø´Ù†Ø§Ø³Ù‡ Ø¢Ù† Ú©Ù„Ø§Ø³ Ù‡Ø§ Ù‡Ø³ØªÙ†Ø¯ØŒ Ø§Ù…Ø§ Ø¨Ø³ÛŒØ§Ø±ÛŒ Ø§Ø² Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù…Ù‚Ø¯Ø§Ø± Ø¹Ø¯Ø¯ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø± Ù†Ø¸Ø± Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ù†Ø¯ Ùˆ Ø¯Ú†Ø§Ø± Ø®Ø·Ø§ Ù…ÛŒ Ø´ÙˆÙ†Ø¯ Ø§Ù…Ø§ Ø¯Ø±Ø®Øªâ€ŒÙ‡Ø§ÛŒ ØªØµÙ…ÛŒÙ… Ú†ÙˆÙ† Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ù‚Ø§ÛŒØ³Ù‡ Ùˆ Ø¨Ø±Ø´ Ø´Ø±Ø·ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¹Ù…Ù„ Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯ Ùˆ Ø±ÙˆÛŒ Ù„ÛŒØ¨Ù„â€ŒÙ‡Ø§ Ø¹Ù…Ù„ÛŒØ§Øª Ø¹Ø¯Ø¯ÛŒ Ø§Ù†Ø¬Ø§Ù… Ù†Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ Ø¯Ú†Ø§Ø± Ø®Ø·Ø§ Ù†Ù…ÛŒ Ø´ÙˆÙ†Ø¯.\n",
    "\n",
    "ØªÙØ§ÙˆØª Ø§ØµÙ„ÛŒ Ø§ÛŒÙ† Ø¯Ùˆ Ø±ÙˆØ´ Ø§ÛŒÙ† Ø¯Ø± Ù†Ø­ÙˆÙ‡ ØªØ¹Ø±ÛŒÙ Ù…Ø³Ø¦Ù„Ù‡ Ø§Ø³Øª. Ø¯Ø± Ø­Ø§Ù„Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Label Encoding Ø¯Ø± ÛŒÚ© Ù…Ø¯Ù„ Ú†Ù†Ø¯Ú©Ù„Ø§Ø³Ù‡ØŒ ÙÙ‚Ø· ÛŒÚ© Ø³ØªÙˆÙ† Ù‡Ø¯Ù Ø¯Ø§Ø±ÛŒÙ… Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ø³Ø³ØªÙ‡â€ŒØ§ÛŒ Ù…Ø«Ù„ 0ØŒ 1 Ùˆ 2 Ø±Ø§ Ù…ÛŒâ€ŒÚ¯ÛŒØ±Ø¯. Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„ØªØŒ Ù…Ø¯Ù„ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ù…Ø±Ø²Ù‡Ø§ÛŒ ØªØµÙ…ÛŒÙ…â€ŒÚ¯ÛŒØ±ÛŒ Ø±Ø§ Ø·ÙˆØ±ÛŒ ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ø¯ Ú©Ù‡ Ù‡Ù…Ù‡ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ø±Ø§ Ù‡Ù…Ø²Ù…Ø§Ù† Ø§Ø² Ù‡Ù… Ø¬Ø¯Ø§ Ú©Ù†Ø¯.\n",
    "\n",
    "Ø§Ù…Ø§ Ø¯Ø± Ø±ÙˆØ´ One-vs-Rest Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² One-Hot LabelsØŒ Ù…Ø³Ø¦Ù„Ù‡ Ú†Ù†Ø¯Ú©Ù„Ø§Ø³Ù‡ Ø¨Ù‡ Ú†Ù†Ø¯ Ù…Ø³Ø¦Ù„Ù‡ Ø¨Ø§ÛŒÙ†Ø±ÛŒ Ù…Ø³ØªÙ‚Ù„ Ø´Ú©Ø³ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ù„Ø§Ø³ ÛŒÚ© Ù…Ø¯Ù„ Ø¬Ø¯Ø§ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ ÙÙ‚Ø· Ù¾Ø§Ø³Ø® ÛŒÚ© Ø³ÙˆØ§Ù„ Ø³Ø§Ø¯Ù‡ Ø±Ø§ Ø¨Ø¯Ù‡Ø¯: Â«Ø¢ÛŒØ§ Ø§ÛŒÙ† Ù†Ù…ÙˆÙ†Ù‡ Ù…ØªØ¹Ù„Ù‚ Ø¨Ù‡ Ø§ÛŒÙ† Ú©Ù„Ø§Ø³ Ù‡Ø³Øª ÛŒØ§ Ù†Ù‡ØŸÂ». Ø¯Ø± Ø§ÛŒÙ† Ø­Ø§Ù„ØªØŒ ØªÙ…Ø§Ù… Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ø¯ÛŒÚ¯Ø± Ø¨Ø§ Ù‡Ù… ÛŒÚ©ÛŒ Ø´Ø¯Ù‡ Ùˆ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ú©Ù„Ø§Ø³ Ù…Ù†ÙÛŒ Ø¯Ø± Ù†Ø¸Ø± Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯. Ø¨Ù‡ Ø§ÛŒÙ† ØªØ±ØªÛŒØ¨ Ù‡Ø± Ù…Ø¯Ù„ ÙÙ‚Ø· Ø±ÙˆÛŒ ØªØ´Ø®ÛŒØµ Ú©Ù„Ø§Ø³ Ø®ÙˆØ¯Ø´ ØªÙ…Ø±Ú©Ø² Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ú©Ø§Ø±ÛŒ Ø¨Ù‡ ØªÙØ§ÙˆØªâ€ŒÙ‡Ø§ÛŒ Ø¬Ø²Ø¦ÛŒ Ø¨ÛŒÙ† Ø³Ø§ÛŒØ± Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ Ù†Ø¯Ø§Ø±Ø¯. Ø§ÛŒÙ† Ø±ÙˆÛŒÚ©Ø±Ø¯ Ù‡Ù… Ù…Ø´Ú©Ù„ ØªØ±ØªÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ú©Ø§Ø°Ø¨ Ø±Ø§ Ø§Ø² Ø¨ÛŒÙ† Ù…ÛŒâ€ŒØ¨Ø±Ø¯ Ùˆ Ù‡Ù… Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ù…Ø¯Ù„â€ŒÙ‡Ø§ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ø´Ø§Ø®Øµ Ù‡Ø± Ú©Ù„Ø§Ø³ Ø±Ø§ ÙˆØ§Ø¶Ø­â€ŒØªØ± ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ù†Ø¯.\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "test_file = \"./test/part3_test.csv\"      \n",
    "output_folder = \"part3_submissions\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "print(f\"Reading test file: {test_file} ...\")\n",
    "df_test = pd.read_csv(test_file)\n",
    "\n",
    "print(\"Preprocessing test data...\")\n",
    "X_test_transformed = preprocessor.transform(df_test)\n",
    "\n",
    "idx_to_label = {0: 'Denial_mode', 1: 'No_issue', 2: 'panic_mode'}\n",
    "\n",
    "def generate_submission(model, X, original_df, filename, model_name):\n",
    "    print(f\"Generating results for: {model_name}...\")\n",
    "    \n",
    "    pred_indices = model.predict(X)\n",
    "    \n",
    "    pred_labels = [idx_to_label[idx] for idx in pred_indices]\n",
    "    \n",
    "    submission = original_df.copy()\n",
    "    submission['predicted_label'] = pred_labels\n",
    "    \n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    submission.to_csv(save_path, index=False)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "generate_submission(\n",
    "    model=dt_model, \n",
    "    X=X_test_transformed, \n",
    "    original_df=df_test,\n",
    "    filename=\"DecisionTree_results.csv\",\n",
    "    model_name=\"Decision Tree (Baseline)\"\n",
    ")\n",
    "\n",
    "generate_submission(\n",
    "    model=best_rf_model, \n",
    "    X=X_test_transformed, \n",
    "    original_df=df_test,\n",
    "    filename=\"RandomForest_results.csv\",\n",
    "    model_name=\"Random Forest (Tuned)\"\n",
    ")\n",
    "\n",
    "generate_submission(\n",
    "    model=best_gb_model, \n",
    "    X=X_test_transformed, \n",
    "    original_df=df_test,\n",
    "    filename=\"GradientBoosting_results.csv\",\n",
    "    model_name=\"Gradient Boosting (Tuned)\"\n",
    ")\n",
    "\n",
    "print(f\"Generating results for: One-vs-Rest (OvR)...\")\n",
    "\n",
    "probs_matrix = np.zeros((len(X_test_transformed), 3))\n",
    "probs_matrix[:, 0] = models[0].predict_proba(X_test_transformed)[:, 1] # Denial\n",
    "probs_matrix[:, 1] = models[1].predict_proba(X_test_transformed)[:, 1] # No_issue\n",
    "probs_matrix[:, 2] = models[2].predict_proba(X_test_transformed)[:, 1] # Panic\n",
    "\n",
    "ovr_indices = np.argmax(probs_matrix, axis=1)\n",
    "ovr_labels = [idx_to_label[idx] for idx in ovr_indices]\n",
    "\n",
    "submission_ovr = df_test.copy()\n",
    "submission_ovr['predicted_label'] = ovr_labels\n",
    "ovr_save_path = os.path.join(output_folder, \"OneVsRest_results.csv\")\n",
    "submission_ovr.to_csv(ovr_save_path, index=False)\n",
    "print(f\"Saved: {ovr_save_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All submissions generated successfully!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
