{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaSBweZwUuOk"
   },
   "source": [
    "# ğŸ¤– AI, CA3, Machine Learning ğŸ“š  \n",
    "\n",
    "* **Name** : Mohammad Sadra ğŸ–Š  \n",
    "* **Last Name** :  Abbasi ğŸ“  \n",
    "* **SID** : 810101469 ğŸ†”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "du8DTCJYUuOr"
   },
   "source": [
    "# IMPORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_col='crisis_type', task_type='classification', \n",
    "                 numerical_strategy='mean', categorical_strategy='most_frequent'):\n",
    "        \"\"\"\n",
    "        task_type: 'classification' (default) -> encodes target labels\n",
    "                   'regression' -> keeps target as continuous numbers\n",
    "        \"\"\"\n",
    "        self.target_col = target_col\n",
    "        self.task_type = task_type \n",
    "        self.num_strategy = numerical_strategy\n",
    "        self.cat_strategy = categorical_strategy\n",
    "        \n",
    "        self.num_imputer = None\n",
    "        self.cat_imputer = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.label_encoders = {}\n",
    "        self.target_encoder = LabelEncoder()\n",
    "        \n",
    "        self.num_cols = []\n",
    "        self.cat_cols = []\n",
    "        self.outlier_bounds = {}\n",
    "\n",
    "    def _feature_engineering(self, df):\n",
    "        df_copy = df.copy()\n",
    "        if 'avg_sleep_last_week' in df_copy.columns and 'sleep_hours_before_exam' in df_copy.columns:\n",
    "            df_copy['sleep_stability'] = abs(df_copy['avg_sleep_last_week'] - df_copy['sleep_hours_before_exam'])\n",
    "        return df_copy\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = self._feature_engineering(X)\n",
    "        \n",
    "        self.num_cols = X.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "        self.cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "        \n",
    "        if self.target_col in self.num_cols: self.num_cols.remove(self.target_col)\n",
    "        if self.target_col in self.cat_cols: self.cat_cols.remove(self.target_col)\n",
    "        \n",
    "        self.num_imputer = SimpleImputer(strategy=self.num_strategy)\n",
    "        self.num_imputer.fit(X[self.num_cols])\n",
    "        \n",
    "        self.cat_imputer = SimpleImputer(strategy=self.cat_strategy)\n",
    "        self.cat_imputer.fit(X[self.cat_cols])\n",
    "        \n",
    "        for col in self.num_cols:\n",
    "            Q1 = X[col].quantile(0.01)\n",
    "            Q3 = X[col].quantile(0.99)\n",
    "            self.outlier_bounds[col] = (Q1, Q3)\n",
    "\n",
    "        for col in self.cat_cols:\n",
    "            le = LabelEncoder()\n",
    "            le.fit(X[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "            \n",
    "        if y is not None and self.task_type == 'classification':\n",
    "            self.target_encoder.fit(y)\n",
    "            \n",
    "        X_temp_num = self.num_imputer.transform(X[self.num_cols])\n",
    "        self.scaler.fit(X_temp_num)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X = self._feature_engineering(X)\n",
    "        \n",
    "        X[self.num_cols] = self.num_imputer.transform(X[self.num_cols])\n",
    "        X[self.cat_cols] = self.cat_imputer.transform(X[self.cat_cols])\n",
    "        \n",
    "        for col in self.num_cols:\n",
    "            lower, upper = self.outlier_bounds[col]\n",
    "            X[col] = np.clip(X[col], lower, upper)\n",
    "            \n",
    "        for col in self.cat_cols:\n",
    "            le = self.label_encoders[col]\n",
    "            X[col] = X[col].astype(str).map(lambda s: s if s in le.classes_ else le.classes_[0])\n",
    "            X[col] = le.transform(X[col])\n",
    "            \n",
    "        X[self.num_cols] = self.scaler.transform(X[self.num_cols].values)\n",
    "        \n",
    "        X_final = np.hstack([X[self.num_cols].values, X[self.cat_cols].values])\n",
    "        \n",
    "        y_transformed = None\n",
    "        if y is not None:\n",
    "            if self.task_type == 'classification':\n",
    "                y_transformed = self.target_encoder.transform(y)\n",
    "            else:\n",
    "                y_transformed = y.values if isinstance(y, pd.Series) else y\n",
    "            \n",
    "        if y is not None:\n",
    "            return X_final, y_transformed\n",
    "        else:\n",
    "            return X_final\n",
    "        \n",
    "    def plot_correlation(self, X, y=None):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        df_temp = pd.DataFrame(X, columns=self.num_cols + self.cat_cols)\n",
    "        \n",
    "        if y is not None:\n",
    "            df_temp[self.target_col] = y\n",
    "            \n",
    "        plt.figure(figsize=(12, 10))\n",
    "        sns.heatmap(df_temp.corr(), annot=True, fmt=\".2f\", cmap='coolwarm', linewidths=0.5)\n",
    "        plt.title(\"Feature Correlation Matrix\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./part4_dataset/part4_dataset.csv')\n",
    "target_col = 'final_exam_score'\n",
    "\n",
    "X = df.drop(columns=[target_col]) \n",
    "y = df[target_col]\n",
    "\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "preprocessor = Preprocessor(target_col=target_col, task_type='regression')\n",
    "\n",
    "preprocessor.fit(X_train_raw, y_train_raw)\n",
    "\n",
    "X_train, y_train = preprocessor.transform(X_train_raw, y_train_raw)\n",
    "X_val, y_val = preprocessor.transform(X_val_raw, y_val_raw)\n",
    "\n",
    "# preprocessor.plot_correlation(X_train, y_train_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "def calc_mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def calc_r2(y_true, y_pred):\n",
    "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    if ss_tot == 0: return 0\n",
    "    return 1 - (ss_res / ss_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.8;\">\n",
    "    <h3 style=\"margin-top: 15px;\">ØªÙˆØ¶ÛŒØ­ Ù…ØªØ±ÛŒÚ© Ù‡Ø§</h3>\n",
    "</div>\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "Ø¨Ù‡ Ø·ÙˆØ± Ú©Ù„ÛŒ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø¨Ø§ ÛŒÚ© Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ù¾ÛŒÙˆØ³ØªÙ‡ Ø³Ø±ÙˆÚ©Ø§Ø± Ø¯Ø§Ø±ÛŒÙ… Ùˆ Ø¨Ø±Ø®Ù„Ø§Ù Ø¨Ø®Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒØŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¯Ù‚ÛŒÙ‚ ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ù…Ø´Ø®Øµ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ù„ÛŒØ¨Ù„ Ø¹Ù…Ù„Ø§ Ø§Ù…Ú©Ø§Ù†â€ŒÙ¾Ø°ÛŒØ± Ù†ÛŒØ³Øª. Ø¯Ø± Ú†Ù†ÛŒÙ† Ù…Ø³Ø§Ø¦Ù„ÛŒØŒ Ù‡Ø¯Ù Ø§ØµÙ„ÛŒ Ø§ÛŒÙ† Ù†ÛŒØ³Øª Ú©Ù‡ Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡ Ø¯Ù‚ÛŒÙ‚Ø§ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ù„Ú©Ù‡ Ù…ÛŒØ²Ø§Ù† Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ù‡Ù…ÛŒØª Ø¯Ø§Ø±Ø¯. Ø¨Ù‡ Ù‡Ù…ÛŒÙ† Ø¯Ù„ÛŒÙ„ØŒ Ø§Ø² Ù…Ø¹ÛŒØ§Ø±Ù‡Ø§ÛŒÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ù†Ø´Ø§Ù† Ø¯Ù‡Ù†Ø¯ Ù…Ø¯Ù„ ØªØ§ Ú†Ù‡ Ø­Ø¯ Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± ØµØ­ÛŒØ­ Ù†Ø²Ø¯ÛŒÚ© Ø´Ø¯Ù‡ Ø§Ø³Øª.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<strong>MSE</strong> ÛŒØ§ Mean Squared Error Ø¨Ø±Ø§Ø¨Ø± Ø¨Ø§ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† ØªÙˆØ§Ù† Ø¯ÙˆÙ… Ø§Ø®ØªÙ„Ø§Ù Ø¨ÛŒÙ† Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ùˆ Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡ Ø§Ø³Øª. Ø¨Ù‡ Ø¯Ù„ÛŒÙ„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ØªÙˆØ§Ù† Ø¯ÙˆÙ…ØŒ Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± Ø¨Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø­Ø³Ø§Ø³â€ŒØªØ± Ø§Ø³Øª Ùˆ Ø¢Ù†â€ŒÙ‡Ø§ Ø±Ø§ Ø¨ÛŒØ´ Ø§Ø² Ø®Ø·Ø§Ù‡Ø§ÛŒ Ú©ÙˆÚ†Ú© Ø¬Ø±ÛŒÙ…Ù‡ Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ØŒ MSE Ø¨ÛŒØ´ØªØ± Ø²Ù…Ø§Ù†ÛŒ Ø§Ù‡Ù…ÛŒØª Ø¯Ø§Ø±Ø¯ Ú©Ù‡ Ø®Ø·Ø§Ù‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯ Ø¨Ø±Ø§ÛŒ Ù…Ø³Ø¦Ù„Ù‡ Ù†Ø§Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø§Ø´Ù†Ø¯.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<strong>MAE</strong> ÛŒØ§ Mean Absolute Error Ù…Ø´Ø®Øµ Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ú©Ù‡ Ù…Ø¯Ù„ Ø¨Ù‡ Ø·ÙˆØ± Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ú†Ù‡ Ù…ÛŒØ²Ø§Ù† Ø§Ø² Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ ÙØ§ØµÙ„Ù‡ Ø¯Ø§Ø±Ø¯. Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± ØªÙØ³ÛŒØ± Ø³Ø§Ø¯Ù‡â€ŒØªØ±ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ MSE Ø¯Ø§Ø±Ø¯ Ùˆ Ø¨Ù‡ ØµÙˆØ±Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ù…ÛŒØ²Ø§Ù† Ø®Ø·Ø§ÛŒ Ù…ØªÙˆØ³Ø· Ù…Ø¯Ù„ Ø±Ø§ Ø¯Ø± Ù‡Ù…Ø§Ù† ÙˆØ§Ø­Ø¯ Ù…ØªØºÛŒØ± Ù‡Ø¯Ù Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "<strong>R<sup>2</sup></strong> ÛŒØ§ Ø¶Ø±ÛŒØ¨ ØªØ¹ÛŒÛŒÙ† Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ú†Ù‡ Ø¯Ø±ØµØ¯ÛŒ Ø§Ø² ØªØºÛŒÛŒØ±Ø§Øª Ù…ØªØºÛŒØ± Ù‡Ø¯Ù ØªÙˆØ³Ø· Ù…Ø¯Ù„ ØªÙˆØ¶ÛŒØ­ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù…Ù‚Ø¯Ø§Ø± Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø± Ø¨ÛŒØ§Ù†Ú¯Ø± Ù…ÛŒØ²Ø§Ù† ØªØ·Ø§Ø¨Ù‚ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙˆØ§Ù‚Ø¹ÛŒ Ù†Ø³Ø¨Øª Ø¨Ù‡ ÛŒÚ© Ù…Ø¯Ù„ Ø³Ø§Ø¯Ù‡ Ù…Ø±Ø¬Ø¹ (Ù…Ø§Ù†Ù†Ø¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†) Ø§Ø³Øª. Ù‡Ø±Ú†Ù‡ Ù…Ù‚Ø¯Ø§Ø± R<sup>2</sup> Ø¨Ù‡ Û± Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ù…Ø¯Ù„ ØªÙˆØ§Ù†Ø³ØªÙ‡ Ø§Ø³Øª Ø§Ù„Ú¯ÙˆÛŒ Ú©Ù„ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±Ø§ Ø¨Ù‡ØªØ± ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±Ø¯ØŒ Ùˆ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾Ø§ÛŒÛŒÙ† ÛŒØ§ Ù…Ù†ÙÛŒ Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¶Ø¹ÛŒÙ Ù…Ø¯Ù„ Ù‡Ø³ØªÙ†Ø¯.\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Decision Tree\n",
      "MSE: 7.0817 | MAE: 1.9918 | R2: 0.6400\n",
      "========================================\n",
      "Model: Random Forest\n",
      "MSE: 6.1310 | MAE: 1.7379 | R2: 0.6883\n",
      "========================================\n",
      "Model: XGBoost\n",
      "MSE: 6.2926 | MAE: 1.7532 | R2: 0.6801\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "regression_models = {\n",
    "    \"Decision Tree\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    \"Random Forest\": RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42),\n",
    "    \"XGBoost\": XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "results_log = []\n",
    "\n",
    "for model_name, regressor in regression_models.items():\n",
    "    regressor.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_val = regressor.predict(X_val)\n",
    "    \n",
    "    mse = calc_mse(y_val, y_pred_val)\n",
    "    mae = calc_mae(y_val, y_pred_val)\n",
    "    r2 = calc_r2(y_val, y_pred_val)\n",
    "    \n",
    "    results_log.append({'Model': model_name, 'R2': r2, 'MSE': mse})\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"MSE: {mse:.4f} | MAE: {mae:.4f} | R2: {r2:.4f}\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### result\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/regression_models_result.png\" width=\"600\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biasâ€“Variance Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "class BiasVarianceAnalyzer:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "        \n",
    "        self.x_star = None\n",
    "        self.y_star_actual = None\n",
    "        self.predictions = {\n",
    "            \"Decision Tree\": [],\n",
    "            \"Random Forest\": [],\n",
    "            \"XGBoost\": []\n",
    "        }\n",
    "\n",
    "    def set_target_point(self, index=0):\n",
    "        if isinstance(self.X_val, pd.DataFrame):\n",
    "            self.x_star = self.X_val.iloc[index : index+1]\n",
    "            self.y_star_actual = self.y_val.iloc[index]\n",
    "        else:\n",
    "            self.x_star = self.X_val[index].reshape(1, -1)\n",
    "            self.y_star_actual = self.y_val[index]\n",
    "            \n",
    "    def run_experiment(self, n_iterations=100, train_ratio=0.3):\n",
    "        self.predictions = {k: [] for k in self.predictions}\n",
    "        \n",
    "        for i in range(n_iterations):\n",
    "            X_sub, _, y_sub, _ = train_test_split(\n",
    "                self.X_train, self.y_train, \n",
    "                train_size=train_ratio, \n",
    "                random_state=i\n",
    "            )\n",
    "            \n",
    "            models = {\n",
    "                \"Decision Tree\": DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "                \"Random Forest\": RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42),\n",
    "                \"XGBoost\": XGBRegressor(n_estimators=50, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "            }\n",
    "            \n",
    "            for name, model in models.items():\n",
    "                model.fit(X_sub, y_sub)\n",
    "                pred = model.predict(self.x_star)[0]\n",
    "                self.predictions[name].append(pred)\n",
    "            \n",
    "        print(\"Experiment completed.\")\n",
    "\n",
    "    def plot_bias_variance(self):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # define the positions of the models\n",
    "        positions = {\n",
    "            \"Decision Tree\": 0,\n",
    "            \"Random Forest\": 1,\n",
    "            \"XGBoost\": 2\n",
    "        }\n",
    "        \n",
    "        colors = {'Decision Tree': 'red', 'Random Forest': 'blue', 'XGBoost': 'green'}\n",
    "        \n",
    "        for name, preds in self.predictions.items():\n",
    "            x_pos = positions[name]\n",
    "            y_vals = preds\n",
    "            \n",
    "            x_vals = np.full(len(y_vals), x_pos)\n",
    "            \n",
    "            plt.scatter(x_vals, y_vals, color=colors[name], alpha=0.3, s=30, label=name)\n",
    "            \n",
    "            mean_pred = np.mean(y_vals)\n",
    "            plt.scatter(x_pos, mean_pred, color='black', marker='X', s=100, zorder=10)\n",
    "\n",
    "        plt.axhline(y=self.y_star_actual, color='gray', linestyle='--', label='Actual Value')\n",
    "        \n",
    "        plt.xticks([0, 1, 2], positions.keys())\n",
    "        plt.ylabel(\"Predicted Value for x_star\")\n",
    "        plt.title(\"Bias-Variance Tradeoff: Model Stability Analysis\")\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "analyzer = BiasVarianceAnalyzer(X_train, y_train, X_val, y_val)\n",
    "analyzer.set_target_point(index=5)\n",
    "analyzer.run_experiment(n_iterations=100, train_ratio=0.3)\n",
    "analyzer.plot_bias_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.8;\">\n",
    "    <h3 style=\"margin-top: 15px;\">Ø®Ø±ÙˆØ¬ÛŒ</h3>\n",
    "</div>\n",
    "\n",
    "<table style=\"width: 100%; text-align: center; margin: 25px 0;\">\n",
    "    <tr>\n",
    "        <td><img src=\"./Assets/model_analysis.png\" width=\"800\"></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-size: 1.05em;\">\n",
    "\n",
    "<p>\n",
    "Ù…ÛŒâ€ŒØªÙˆØ§Ù† Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©Ø±Ø¯ Ú©Ù‡ Ù…Ø¯Ù„ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø¯Ø§Ø±Ø¯Ø› Ø¨Ù‡ Ø§ÛŒÙ† Ù…Ø¹Ù†Ø§ Ú©Ù‡ Ù…Ù‚Ø§Ø¯ÛŒØ± Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒØ´Ø¯Ù‡ Ø¢Ù† Ø±ÙˆÛŒ Ø®Ø· Ø§ÙÙ‚ÛŒ Ù¾Ø±Ø§Ú©Ù†Ø¯Ú¯ÛŒ Ø²ÛŒØ§Ø¯ÛŒ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ ØªØ±Ø§Ú©Ù… Ù†Ù‚Ø§Ø· Ù¾Ø§ÛŒÛŒÙ†â€ŒØªØ± Ø§Ø³Øª. Ø§ÛŒÙ† Ø±ÙØªØ§Ø± Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ø¯ Ú©Ù‡ Ø¨Ø§ Ù‡Ø± Ø¨Ø§Ø± Ø§Ù†ØªØ®Ø§Ø¨ ØªØµØ§Ø¯ÙÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒØŒ Ø®Ø±ÙˆØ¬ÛŒ Ù…Ø¯Ù„ Ø¨Ù‡ Ø´Ú©Ù„ Ù…Ø­Ø³ÙˆØ³ÛŒ ØªØºÛŒÛŒØ± Ù…ÛŒâ€ŒÚ©Ù†Ø¯ Ùˆ Ù…Ø¯Ù„ Ø§Ø² Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ú©Ù…ØªØ±ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ø§Ø³Øª. Ø¯Ø± Ù…Ù‚Ø§Ø¨Ù„ØŒ Ø¯Ùˆ Ù…Ø¯Ù„ Random Forest Ùˆ XGBoost ØªØ±Ø§Ú©Ù… Ø¨Ø§Ù„Ø§ØªØ±ÛŒ Ø§Ø² Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ø±Ø§ Ø¯Ø± Ø§Ø·Ø±Ø§Ù ÛŒÚ© Ù…Ù‚Ø¯Ø§Ø± Ù…Ø´Ø®Øµ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯ Ú©Ù‡ Ø¨ÛŒØ§Ù†Ú¯Ø± ÙˆØ§Ø±ÛŒØ§Ù†Ø³ Ú©Ù…ØªØ± Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ø¨ÛŒØ´ØªØ± Ø¢Ù†â€ŒÙ‡Ø§ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ø§Ø³Øª.\n",
    "\n",
    "Ø¯Ø± Ù…ÙˆØ±Ø¯ Ø¨Ø§ÛŒØ§Ø³ØŒ Ù‡Ø±Ú†Ù‡ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ Ú©Ù‡ Ø¯Ø± Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø§ Ø¹Ù„Ø§Ù…Øª Ø¶Ø±Ø¨Ø¯Ø± Ø³ÛŒØ§Ù‡ Ù…Ø´Ø®Øµ Ø´Ø¯Ù‡ Ø§Ø³Øª Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø¨Ø§Ø´Ø¯ØŒ Ø¨Ø§ÛŒØ§Ø³ Ù…Ø¯Ù„ Ú©Ù…ØªØ± Ø®ÙˆØ§Ù‡Ø¯ Ø¨ÙˆØ¯. Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÛŒÙ† Ù…Ø¹ÛŒØ§Ø±ØŒ Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ú©Ù‡ Ù…Ø¯Ù„ Random Forest Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†ÛŒ Ù†Ø²Ø¯ÛŒÚ©â€ŒØªØ± Ø¨Ù‡ Ù…Ù‚Ø¯Ø§Ø± ÙˆØ§Ù‚Ø¹ÛŒ Ø¯Ø§Ø±Ø¯ Ùˆ Ø¯Ø± Ù†ØªÛŒØ¬Ù‡ Ù†Ø³Ø¨Øª Ø¨Ù‡ Ø¯Ùˆ Ù…Ø¯Ù„ Ø¯ÛŒÚ¯Ø± Ø§Ø² Ø¨Ø§ÛŒØ§Ø³ Ú©Ù…ØªØ±ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ø§Ø³ØªØŒ Ø¯Ø± Ø­Ø§Ù„ÛŒ Ú©Ù‡ Ù…Ø¯Ù„ Ø¯Ø±Ø®Øª ØªØµÙ…ÛŒÙ… Ùˆ XGBoost ÙØ§ØµÙ„Ù‡ Ø¨ÛŒØ´ØªØ±ÛŒ Ø¨Ø§ Ù…Ù‚Ø¯Ø§Ø± Ø­Ù‚ÛŒÙ‚ÛŒ Ù†Ø´Ø§Ù† Ù…ÛŒâ€ŒØ¯Ù‡Ù†Ø¯.\n",
    "</p>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data loaded successfully.\n",
      "Generating results for: Decision Tree...\n",
      "Saved: part4_submissions/DecisionTree_Part4.csv\n",
      "Generating results for: Random Forest...\n",
      "Saved: part4_submissions/RandomForest_Part4.csv\n",
      "Generating results for: XGBoost...\n",
      "Saved: part4_submissions/XGBoost_Part4.csv\n",
      "\n",
      "==================================================\n",
      "All Part 4 submissions generated successfully!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "test_file = \"./test/part4_test.csv\" \n",
    "output_folder = \"part4_submissions\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "try:\n",
    "    df_test = pd.read_csv(test_file)\n",
    "    print(\"Test data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: Test file not found!\")\n",
    "    df_test = pd.DataFrame(columns=X_train.columns)\n",
    "\n",
    "X_test_transformed = preprocessor.transform(df_test)\n",
    "\n",
    "# train models\n",
    "dt = DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "rf = RandomForestRegressor(n_estimators=50, max_depth=10, random_state=42)\n",
    "xgb = XGBRegressor(n_estimators=50, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "def generate_submission(model, X, original_df, filename, model_name):\n",
    "    print(f\"Generating results for: {model_name}...\")\n",
    "    preds = model.predict(X)\n",
    "    submission = original_df.copy()\n",
    "    submission['label'] = preds\n",
    "    save_path = os.path.join(output_folder, filename)\n",
    "    submission.to_csv(save_path, index=False)\n",
    "    print(f\"Saved: {save_path}\")\n",
    "\n",
    "generate_submission(\n",
    "    model= dt,\n",
    "    X=X_test_transformed, \n",
    "    original_df=df_test,\n",
    "    filename=\"DecisionTree_Part4.csv\",\n",
    "    model_name=\"Decision Tree\"\n",
    ")\n",
    "\n",
    "\n",
    "generate_submission(\n",
    "    model=rf, \n",
    "    X=X_test_transformed, \n",
    "    original_df=df_test,\n",
    "    filename=\"RandomForest_Part4.csv\",\n",
    "    model_name=\"Random Forest\"\n",
    ")\n",
    "\n",
    "generate_submission(\n",
    "    model=xgb, \n",
    "    X=X_test_transformed, \n",
    "    original_df=df_test,\n",
    "    filename=\"XGBoost_Part4.csv\",\n",
    "    model_name=\"XGBoost\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"All Part 4 submissions generated successfully!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
