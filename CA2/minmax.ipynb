{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5a3554b",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "# <span style=\"color: #3498db;\">CA2 - Genetic and Games Algorithm</span>\n",
    "\n",
    "**<span style=\"color:rgb(247, 169, 0);\">[Mohammad Sadra Abbasi]</span> - <span style=\"color:rgb(143, 95, 195);\">[810101469]</span>**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d852d2a",
   "metadata": {},
   "source": [
    "# <span style=\"color: #3498db;\">Dots and Boxes with Minimax Algorithm</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb367e8b",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7344defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "from tkinter import *\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional, Tuple\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd8376",
   "metadata": {},
   "source": [
    "## GameState Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5393790",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GameState:\n",
    "    board_status: np.ndarray  # shape (n-1, n-1)\n",
    "    row_status: np.ndarray    # shape (n, n-1)\n",
    "    col_status: np.ndarray    # shape (n-1, n)\n",
    "    player1_turn: bool\n",
    "\n",
    "    def clone(self) -> \"GameState\":\n",
    "        \"\"\"Creates a deep copy of the current game state.\"\"\"\n",
    "        return GameState(\n",
    "            board_status=self.board_status.copy(),\n",
    "            row_status=self.row_status.copy(),\n",
    "            col_status=self.col_status.copy(),\n",
    "            player1_turn=self.player1_turn,\n",
    "        )\n",
    "\n",
    "    def get_dimensions(self) -> int:\n",
    "        \"\"\"Returns the number of dots (n) in the game grid.\"\"\"\n",
    "        return self.row_status.shape[0]\n",
    "\n",
    "    def is_gameover(self) -> bool:\n",
    "        \"\"\"Checks if all edges have been drawn.\"\"\"\n",
    "        return (self.row_status == 1).all() and (self.col_status == 1).all()\n",
    "\n",
    "    def get_scores(self) -> Tuple[int, int]:\n",
    "        \"\"\"Returns (player1_score, player2_score).\"\"\"\n",
    "        p1 = int(np.count_nonzero(self.board_status == -4))\n",
    "        p2 = int(np.count_nonzero(self.board_status == 4))\n",
    "        return p1, p2\n",
    "\n",
    "    def available_moves(self) -> List[Tuple[str, List[int]]]:\n",
    "        \"\"\"Returns a list of all valid moves as (move_type, [row, col]).\"\"\"\n",
    "        moves = []\n",
    "        for c in range(self.row_status.shape[0]):\n",
    "            for r in range(self.row_status.shape[1]):\n",
    "                if self.row_status[c, r] == 0:\n",
    "                    moves.append((\"row\", [r, c]))\n",
    "\n",
    "        for c in range(self.col_status.shape[0]):\n",
    "            for r in range(self.col_status.shape[1]):\n",
    "                if self.col_status[c, r] == 0:\n",
    "                    moves.append((\"col\", [r, c]))\n",
    "\n",
    "        return moves\n",
    "\n",
    "    def apply_move(self, move_type: str, logical_position: List[int]) -> bool:\n",
    "        \"\"\"\n",
    "        Applies a move to the game state.\n",
    "        Returns True if a box was completed, False otherwise.\n",
    "        \"\"\"\n",
    "        r = logical_position[0]\n",
    "        c = logical_position[1]\n",
    "        val = 1\n",
    "        player_modifier = -1 if self.player1_turn else 1\n",
    "\n",
    "        scored = False\n",
    "        n_dots = self.get_dimensions()\n",
    "\n",
    "        if c < (n_dots - 1) and r < (n_dots - 1):\n",
    "            cur = abs(self.board_status[c, r]) + val\n",
    "            self.board_status[c, r] = cur * player_modifier\n",
    "            if abs(self.board_status[c, r]) == 4:\n",
    "                scored = True\n",
    "\n",
    "        if move_type == \"row\":\n",
    "            self.row_status[c, r] = 1\n",
    "            if c >= 1:\n",
    "                cur = abs(self.board_status[c - 1, r]) + val\n",
    "                self.board_status[c - 1, r] = cur * player_modifier\n",
    "                if abs(self.board_status[c - 1, r]) == 4:\n",
    "                    scored = True\n",
    "\n",
    "        elif move_type == \"col\":\n",
    "            self.col_status[c, r] = 1\n",
    "            if r >= 1:\n",
    "                cur = abs(self.board_status[c, r - 1]) + val\n",
    "                self.board_status[c, r - 1] = cur * player_modifier\n",
    "                if abs(self.board_status[c, r - 1]) == 4:\n",
    "                    scored = True\n",
    "\n",
    "        return scored"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000896d7",
   "metadata": {},
   "source": [
    "## MinimaxAgent Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b1cc24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinimaxAgent:\n",
    "    def __init__(self, isPlayer1: bool = False, use_pruning: bool = True , heuristic_id: int = 1, debug_tree: bool = False):\n",
    "        \"\"\"\n",
    "        Initialize the Minimax agent.\n",
    "        Args:\n",
    "            isPlayer1: True if this agent is Player 1, False if Player 2\n",
    "        \"\"\"\n",
    "        self.node_count = 0\n",
    "        self.isPlayer1 = isPlayer1\n",
    "        self.use_pruning = use_pruning\n",
    "        self.heuristic_id = heuristic_id\n",
    "        self.debug_tree = debug_tree\n",
    "    \n",
    "    def _dbg(self, *args, **kwargs):\n",
    "        if self.debug_tree:\n",
    "            print(*args, **kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def heuristic1(state: GameState, agentIsPlayer1: bool) -> float:\n",
    "        p1, p2 = state.get_scores()\n",
    "        score = (p1 - p2) if agentIsPlayer1 else (p2 - p1)\n",
    "\n",
    "        value = score * 200\n",
    "\n",
    "        board = np.abs(state.board_status)\n",
    "        threes = np.count_nonzero(board == 3)\n",
    "        twos   = np.count_nonzero(board == 2)\n",
    "\n",
    "        maximizing_turn = MinimaxAgent._is_maximizing_turn(state, agentIsPlayer1)\n",
    "\n",
    "        value -= threes * 150\n",
    "\n",
    "        if maximizing_turn:\n",
    "            # value += threes * 150\n",
    "            value -= twos * 50\n",
    "        else:\n",
    "            # value -= threes * 200\n",
    "            value += twos * 20\n",
    "\n",
    "        return value\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def heuristic2(state: GameState, agentIsPlayer1: bool) -> float:\n",
    "        p1, p2 = state.get_scores()\n",
    "        score = (p1 - p2) if agentIsPlayer1 else (p2 - p1)\n",
    "\n",
    "        value = score * 200\n",
    "\n",
    "        board = np.abs(state.board_status)\n",
    "        threes = np.count_nonzero(board == 3)\n",
    "        twos   = np.count_nonzero(board == 2)\n",
    "\n",
    "        maximizing_turn = MinimaxAgent._is_maximizing_turn(state, agentIsPlayer1)\n",
    "\n",
    "        value -= threes * 150\n",
    "\n",
    "        if maximizing_turn:\n",
    "            value -= twos * 40\n",
    "        else:\n",
    "            value -= threes * 400\n",
    "            value += twos * 15\n",
    "\n",
    "        # ----------------------------\n",
    "        #      Potential Lookahead\n",
    "        # ----------------------------\n",
    "\n",
    "        available = state.available_moves()\n",
    "        n = len(available)\n",
    "\n",
    "        # potential_weight = min(1.3, 0.25 + (25 - n) * 0.035) <--- it works for 4x4 board size\n",
    "\n",
    "        dims = state.get_dimensions()\n",
    "        total_possible_moves = 2 * dims * (dims - 1)\n",
    "        max_val = total_possible_moves + 1\n",
    "        potential_weight = min(1.3, 0.25 + (max_val - n) * 0.035)\n",
    "\n",
    "        potential_sum = 0\n",
    "\n",
    "        for move_type, pos in available:\n",
    "            test = state.clone()\n",
    "            mover_is_me = MinimaxAgent._is_maximizing_turn(test, agentIsPlayer1)\n",
    "\n",
    "            scored = test.apply_move(move_type, pos)\n",
    "\n",
    "            after = np.abs(test.board_status)\n",
    "            new_threes = np.count_nonzero(after == 3) - threes\n",
    "            new_twos = np.count_nonzero(after == 2) - twos\n",
    "\n",
    "            move_value = 0\n",
    "\n",
    "            if mover_is_me:\n",
    "                if scored:\n",
    "                    move_value += 220\n",
    "                    move_value -= new_threes * 120\n",
    "                    move_value -= new_twos * 40\n",
    "                else:\n",
    "                    move_value -= new_threes * 150\n",
    "                    move_value += new_twos * 15\n",
    "            else:\n",
    "                if scored:\n",
    "                    move_value -= 250\n",
    "                    move_value -= new_threes * 150\n",
    "                    move_value += new_twos * 20\n",
    "                else:\n",
    "                    move_value += new_threes * 100\n",
    "                    move_value -= new_twos * 35\n",
    "\n",
    "            potential_sum += move_value\n",
    "\n",
    "        if n > 0:\n",
    "            value += (potential_sum / n) * potential_weight\n",
    "\n",
    "        return value\n",
    "\n",
    "    \n",
    "    def _evaluate(self, state: GameState, agentIsPlayer1: bool) -> float:\n",
    "        if (self.heuristic_id == 1):\n",
    "            return MinimaxAgent.heuristic1(state, agentIsPlayer1)\n",
    "        elif (self.heuristic_id == 2):\n",
    "            return MinimaxAgent.heuristic2(state, agentIsPlayer1)\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _is_maximizing_turn(state: GameState, agentIsPlayer1: bool) -> bool:\n",
    "        return state.player1_turn == agentIsPlayer1\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _order_moves(state: GameState, moves: List[Tuple[str, List[int]]]) -> List[Tuple[str, List[int]]]:\n",
    "        \"\"\"\n",
    "        Helper method (PROVIDED): Orders moves for better alpha-beta pruning efficiency.\n",
    "        Prioritizes moves that complete boxes, then safe moves, then risky moves.\n",
    "        You can use this in your choose_move() and _minimax() methods.\n",
    "        \"\"\"\n",
    "        completing_moves = []\n",
    "        safe_moves = []\n",
    "        risky_moves = []\n",
    "\n",
    "        for move_type, pos in moves:\n",
    "            test_state = state.clone()\n",
    "            scored = test_state.apply_move(move_type, pos)\n",
    "\n",
    "            if scored:\n",
    "                completing_moves.append((move_type, pos))\n",
    "            else:\n",
    "                boxes_at_3 = int(np.count_nonzero(np.abs(test_state.board_status) == 3))\n",
    "                if boxes_at_3 > int(np.count_nonzero(np.abs(state.board_status) == 3)):\n",
    "                    risky_moves.append((move_type, pos))\n",
    "                else:\n",
    "                    safe_moves.append((move_type, pos))\n",
    "\n",
    "        return completing_moves + safe_moves + risky_moves\n",
    "\n",
    "    def choose_move(\n",
    "        self, state: GameState, max_depth: Optional[int] = None\n",
    "    ) -> Tuple[Optional[str], Optional[List[int]], float]:\n",
    "        # set default max_depth\n",
    "        if max_depth is None:\n",
    "            max_depth = 4\n",
    "\n",
    "        # end game if no moves\n",
    "        moves = state.available_moves()\n",
    "        if not moves:\n",
    "            return None, None, 0.0\n",
    "        \n",
    "        self.node_count = 0\n",
    "    \n",
    "        ordered_moves = self._order_moves(state, moves)\n",
    "        best_val = -math.inf\n",
    "        best_move = None\n",
    "        \n",
    "        alpha = -math.inf\n",
    "        beta = math.inf\n",
    "\n",
    "        for move_type, pos in ordered_moves:\n",
    "            next_state = state.clone()\n",
    "            scored = next_state.apply_move(move_type, pos)\n",
    "            # print(\"Scored =\", scored)\n",
    "\n",
    "            if scored:\n",
    "                val = self._minimax(next_state, 1, max_depth, alpha, beta, True)\n",
    "            else:\n",
    "                next_state.player1_turn = not next_state.player1_turn\n",
    "                val = self._minimax(next_state, 1, max_depth, alpha, beta, False)\n",
    "\n",
    "            if val > best_val:\n",
    "                best_val = val\n",
    "                best_move = (move_type, pos)\n",
    "            \n",
    "            alpha = max(alpha, val)\n",
    "            \n",
    "        if best_move:\n",
    "            return best_move[0], best_move[1], best_val\n",
    "        else:\n",
    "            return moves[0][0], moves[0][1], best_val\n",
    "\n",
    "    def _minimax(self, state, depth, max_depth, alpha, beta, maximizing, indent=\"\"):\n",
    "\n",
    "        self.node_count += 1\n",
    "        self._dbg(indent, f\"Node d={depth} | max={maximizing} | α={alpha} | β={beta}\")\n",
    "    \n",
    "        if depth == max_depth or state.is_gameover():\n",
    "            return self._evaluate(state, self.isPlayer1)\n",
    "    \n",
    "        moves = state.available_moves()\n",
    "        ordered_moves = self._order_moves(state, moves)\n",
    "    \n",
    "        if maximizing:\n",
    "            max_eval = -math.inf\n",
    "            for move_type, pos in ordered_moves:\n",
    "            \n",
    "                self._dbg(indent, f\"   Try { (move_type, pos) }\")\n",
    "    \n",
    "                next_state = state.clone()\n",
    "                scored = next_state.apply_move(move_type, pos)\n",
    "                # print(\"Scored =\", scored)\n",
    "\n",
    "    \n",
    "                if scored:\n",
    "                    eval = self._minimax(next_state, depth+1, max_depth, alpha, beta, True, indent+\"   \")\n",
    "                else:\n",
    "                    next_state.player1_turn = not next_state.player1_turn\n",
    "                    eval = self._minimax(next_state, depth+1, max_depth, alpha, beta, False, indent+\"   \")\n",
    "    \n",
    "                old_alpha = alpha\n",
    "                max_eval = max(max_eval, eval)\n",
    "                alpha = max(alpha, eval)\n",
    "    \n",
    "                self._dbg(indent, f\"      child={eval} | α:{old_alpha}→{alpha} | β={beta}\")\n",
    "    \n",
    "                if self.use_pruning and beta <= alpha:\n",
    "                    self._dbg(indent, f\"   ✂ Pruned because β({beta}) ≤ α({alpha})\")\n",
    "                    break\n",
    "                \n",
    "            return max_eval\n",
    "    \n",
    "        else:\n",
    "            min_eval = math.inf\n",
    "            for move_type, pos in ordered_moves:\n",
    "            \n",
    "                self._dbg(indent, f\"   Try { (move_type, pos) }\")\n",
    "    \n",
    "                next_state = state.clone()\n",
    "                scored = next_state.apply_move(move_type, pos)\n",
    "                # print(\"Scored =\", scored)\n",
    "\n",
    "    \n",
    "                if scored:\n",
    "                    eval = self._minimax(next_state, depth+1, max_depth, alpha, beta, False, indent+\"   \")\n",
    "                else:\n",
    "                    next_state.player1_turn = not next_state.player1_turn\n",
    "                    eval = self._minimax(next_state, depth+1, max_depth, alpha, beta, True, indent+\"   \")\n",
    "    \n",
    "                old_beta = beta\n",
    "                min_eval = min(min_eval, eval)\n",
    "                beta = min(beta, eval)\n",
    "    \n",
    "                self._dbg(indent, f\"      child={eval} | α={alpha} | β:{old_beta}→{beta}\")\n",
    "    \n",
    "                if self.use_pruning and beta <= alpha:\n",
    "                    self._dbg(indent, f\"   ✂ Pruned because β({beta}) ≤ α({alpha})\")\n",
    "                    break\n",
    "                \n",
    "            return min_eval\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860ff42",
   "metadata": {},
   "source": [
    "## Testing Your Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94643953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class RandomAgent:\n",
    "    def choose_move(self, state: GameState):\n",
    "        moves = state.available_moves()\n",
    "        if not moves:\n",
    "            return None, None, 0\n",
    "        \n",
    "        move = random.choice(moves)\n",
    "        return move[0], move[1], 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b7c6fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for creating initial game states (useful for testing)\n",
    "def make_initial_state(number_of_dots: int, player1_starts: bool = True) -> GameState:\n",
    "    \"\"\"\n",
    "    Creates a new game state with an empty board.\n",
    "    \"\"\"\n",
    "    board_status = np.zeros((number_of_dots - 1, number_of_dots - 1), dtype=int)\n",
    "    row_status = np.zeros((number_of_dots, number_of_dots - 1), dtype=int)\n",
    "    col_status = np.zeros((number_of_dots - 1, number_of_dots), dtype=int)\n",
    "    return GameState(\n",
    "        board_status=board_status, \n",
    "        row_status=row_status, \n",
    "        col_status=col_status, \n",
    "        player1_turn=player1_starts\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8da5e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_simulation(agent_depth, use_pruning, heuristic_id, num_games=20, board_size=3 , debug_tree=False):\n",
    "    wins = 0\n",
    "    losses = 0\n",
    "    ties = 0\n",
    "    total_nodes = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    minimax_bot = MinimaxAgent(isPlayer1=False, use_pruning=use_pruning, heuristic_id=heuristic_id , debug_tree=debug_tree)\n",
    "    random_bot = RandomAgent()\n",
    "\n",
    "    for i in range(num_games):\n",
    "        initial_state = make_initial_state(board_size, player1_starts=True)\n",
    "        state = initial_state\n",
    "        \n",
    "        game_nodes = 0\n",
    "        \n",
    "        while not state.is_gameover():\n",
    "            if state.player1_turn: \n",
    "                m_type, pos, _ = random_bot.choose_move(state)\n",
    "                \n",
    "                scored = state.apply_move(m_type, pos)\n",
    "                \n",
    "                if not scored:\n",
    "                     state.player1_turn = False\n",
    "                     \n",
    "            else: \n",
    "                start_move = time.time()\n",
    "                m_type, pos, _ = minimax_bot.choose_move(state, max_depth=agent_depth)\n",
    "                end_move = time.time()\n",
    "                \n",
    "                total_time += (end_move - start_move)\n",
    "                game_nodes += minimax_bot.node_count\n",
    "                \n",
    "                scored = state.apply_move(m_type, pos)\n",
    "                \n",
    "                if not scored:\n",
    "                     state.player1_turn = True \n",
    "        \n",
    "        p1, p2 = state.get_scores()\n",
    "        if p2 > p1: wins += 1\n",
    "        elif p1 > p2: losses += 1\n",
    "        else: ties += 1\n",
    "            \n",
    "        total_nodes += game_nodes\n",
    "\n",
    "    if num_games > 0:\n",
    "        avg_time_per_game = total_time / num_games\n",
    "        avg_nodes = total_nodes / num_games\n",
    "        win_rate = (wins / num_games) * 100\n",
    "    else:\n",
    "        avg_time_per_game, avg_nodes, win_rate = 0, 0, 0\n",
    "    \n",
    "    return {\n",
    "        \"Depth\": agent_depth,\n",
    "        \"Pruning\": \"On\" if use_pruning else \"Off\",\n",
    "        \"Heuristic\": f\"H{heuristic_id}\",\n",
    "        \"Win Rate (%)\": win_rate,\n",
    "        \"Avg Nodes\": int(avg_nodes),\n",
    "        \"Avg Time (s)\": round(avg_time_per_game, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94fccda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_clean_results(df):\n",
    "    clean_df = df.copy()\n",
    "    \n",
    "    clean_df['Win Rate (%)'] = clean_df['Win Rate (%)'].apply(lambda x: f\"{x:.1f} %\")\n",
    "    \n",
    "    clean_df['Avg Time (s)'] = clean_df['Avg Time (s)'].apply(lambda x: f\"{x:.4f} s\")\n",
    "    \n",
    "    clean_df['Avg Nodes'] = clean_df['Avg Nodes'].apply(lambda x: f\"{x:,}\")\n",
    "    \n",
    "    from IPython.display import display\n",
    "    display(clean_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ea290",
   "metadata": {},
   "source": [
    "## Symple Runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49e45b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Heuristics...\n",
      "Running Heuristic 1...\n",
      "Running Heuristic 2...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Depth</th>\n",
       "      <th>Pruning</th>\n",
       "      <th>Heuristic</th>\n",
       "      <th>Win Rate (%)</th>\n",
       "      <th>Avg Nodes</th>\n",
       "      <th>Avg Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>On</td>\n",
       "      <td>H1</td>\n",
       "      <td>100.0 %</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0005 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>On</td>\n",
       "      <td>H2</td>\n",
       "      <td>100.0 %</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0004 s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Depth Pruning Heuristic Win Rate (%) Avg Nodes Avg Time (s)\n",
       "0      3      On        H1      100.0 %        12     0.0005 s\n",
       "1      3      On        H2      100.0 %        12     0.0004 s"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "test_depth = 3\n",
    "board_size = 2\n",
    "games_per_test = 30\n",
    "\n",
    "print(\"Comparing Heuristics...\")\n",
    "\n",
    "print(\"Running Heuristic 1...\")\n",
    "res_h1 = play_simulation(agent_depth=test_depth, use_pruning=True, heuristic_id=1, num_games=games_per_test, board_size=board_size)\n",
    "results.append(res_h1)\n",
    "\n",
    "print(\"Running Heuristic 2...\")\n",
    "res_h2 = play_simulation(agent_depth=test_depth, use_pruning=True, heuristic_id=2, num_games=games_per_test, board_size=board_size)\n",
    "results.append(res_h2)\n",
    "\n",
    "df_compare = pd.DataFrame(results)\n",
    "display_clean_results(df_compare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652187a",
   "metadata": {},
   "source": [
    "## بررسی نتایج به ازای عمق ها و حالت های مختلف"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm \n",
    "\n",
    "def run_comprehensive_benchmark(num_games=50, board_size=3):    \n",
    "    heuristics = [1, 2]\n",
    "    depths = [2, 4, 6]\n",
    "    # pruning_options = [False, True]\n",
    "    pruning_options = [True]\n",
    "\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    total_iterations = len(heuristics) * len(depths) * len(pruning_options)\n",
    "    \n",
    "    print(f\"Starting Comprehensive Benchmark...\")\n",
    "    print(f\"Settings: Board Size={board_size}x{board_size} | Games per scenario={num_games}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    with tqdm(total=total_iterations, desc=\"Total Progress\") as pbar:\n",
    "        \n",
    "        for h_id in heuristics:\n",
    "            for d in depths:\n",
    "                for prune in pruning_options:\n",
    "                    current_games = num_games\n",
    "\n",
    "                    if d >= 6 and not prune:\n",
    "                        current_games = 2\n",
    "                    \n",
    "                    stats = play_simulation(\n",
    "                        agent_depth=d, \n",
    "                        use_pruning=prune, \n",
    "                        heuristic_id=h_id, \n",
    "                        num_games=current_games, \n",
    "                        board_size=board_size\n",
    "                    )\n",
    "                    \n",
    "                    results.append({\n",
    "                        \"Heuristic\": f\"H{h_id}\",\n",
    "                        \"Depth\": d,\n",
    "                        \"Pruning\": \"Yes\" if prune else \"No\",\n",
    "                        \"Win Rate\": stats[\"Win Rate (%)\"],\n",
    "                        \"Avg Nodes\": stats[\"Avg Nodes\"],\n",
    "                        \"Avg Time\": stats[\"Avg Time (s)\"],\n",
    "                        \"Total Games\": current_games\n",
    "                    })\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "\n",
    "def display_master_table(df):\n",
    "    clean_df = df.copy()\n",
    "    try:\n",
    "        clean_df['Win Rate'] = clean_df['Win Rate'].apply(lambda x: f\"{x:.1f}%\" if isinstance(x, (int, float)) else x)\n",
    "        clean_df['Avg Time'] = clean_df['Avg Time'].apply(lambda x: f\"{x:.4f}s\" if isinstance(x, (int, float)) else x)\n",
    "        clean_df['Avg Nodes'] = clean_df['Avg Nodes'].apply(lambda x: f\"{x:,}\" if isinstance(x, (int, float)) else x)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    clean_df = clean_df.sort_values(by=['Heuristic', 'Depth', 'Pruning'])\n",
    "    \n",
    "    from IPython.display import display\n",
    "    display(clean_df)\n",
    "\n",
    "final_df = run_comprehensive_benchmark(num_games=10, board_size=4)\n",
    "\n",
    "print(\"\\nBenchmark Completed!:\")\n",
    "display_master_table(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7042d048",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; gap: 10px;\">\n",
    "  <div style=\"flex: 1; text-align: center;\">\n",
    "    <h3>3*3 Board Size</h3>\n",
    "    <img src=\"dataframe_3*3.png\" width=\"100%\">\n",
    "  </div>\n",
    "  <div style=\"flex: 1; text-align: center;\">\n",
    "    <h3>4*4 Board Size</h3>\n",
    "    <img src=\"dataframe_4*4.png\" width=\"100%\">\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901885de",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Dots and Boxes Game Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416d03e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Game Configuration\n",
    "MAX_AI_DEPTH = 3\n",
    "\n",
    "size_of_board = 600\n",
    "number_of_dots = 6\n",
    "symbol_size = (size_of_board / 3 - size_of_board / 8) / 2\n",
    "symbol_thickness = 50\n",
    "dot_color = \"#FFFFFF\"\n",
    "player1_color = '#0492CF'\n",
    "player1_color_light = '#67B0CF'\n",
    "player2_color = '#EE4035'\n",
    "player2_color_light = '#EE7E77'\n",
    "text_color = \"#FFFFFF\"\n",
    "dot_width = 0.25*size_of_board/number_of_dots\n",
    "edge_width = 0.1*size_of_board/number_of_dots\n",
    "distance_between_dots = size_of_board / (number_of_dots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10018e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dots_and_Boxes():\n",
    "    def __init__(self):\n",
    "        self.window = Tk()\n",
    "        self.window.title('Dots_and_Boxes')\n",
    "        self.canvas = Canvas(self.window, width=size_of_board, height=size_of_board)\n",
    "        self.canvas.pack()\n",
    "        self.window.bind('<Button-1>', self.click)\n",
    "        self.player1_starts = True\n",
    "        self.ai_agent = MinimaxAgent(isPlayer1=False)\n",
    "        self.ai_mode = True\n",
    "        self.ai_max_depth = MAX_AI_DEPTH\n",
    "        self.refresh_board()\n",
    "        self.play_again()\n",
    "\n",
    "    def play_again(self):\n",
    "        self.refresh_board()\n",
    "        self.board_status = np.zeros(shape=(number_of_dots - 1, number_of_dots - 1))\n",
    "        self.row_status = np.zeros(shape=(number_of_dots, number_of_dots - 1))\n",
    "        self.col_status = np.zeros(shape=(number_of_dots - 1, number_of_dots))\n",
    "        self.pointsScored = False\n",
    "        self.player1_starts = not self.player1_starts\n",
    "        self.player1_turn = self.player1_starts\n",
    "        self.reset_board = False\n",
    "        self.turntext_handle = []\n",
    "        self.already_marked_boxes = []\n",
    "        self.ai_agent.isPlayer1 = False\n",
    "        self.display_turn_text()\n",
    "        self.ai_move_if_needed()\n",
    "\n",
    "    def mainloop(self):\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def is_grid_occupied(self, logical_position, type):\n",
    "        r = logical_position[0]\n",
    "        c = logical_position[1]\n",
    "        occupied = True\n",
    "        if type == 'row' and self.row_status[c][r] == 0:\n",
    "            occupied = False\n",
    "        if type == 'col' and self.col_status[c][r] == 0:\n",
    "            occupied = False\n",
    "        return occupied\n",
    "\n",
    "    def convert_grid_to_logical_position(self, grid_position):\n",
    "        grid_position = np.array(grid_position)\n",
    "        position = (grid_position-distance_between_dots/4)//(distance_between_dots/2)\n",
    "\n",
    "        type = False\n",
    "        logical_position = []\n",
    "        if position[1] % 2 == 0 and (position[0] - 1) % 2 == 0:\n",
    "            r = int((position[0]-1)//2)\n",
    "            c = int(position[1]//2)\n",
    "            logical_position = [r, c]\n",
    "            type = 'row'\n",
    "        elif position[0] % 2 == 0 and (position[1] - 1) % 2 == 0:\n",
    "            c = int((position[1] - 1) // 2)\n",
    "            r = int(position[0] // 2)\n",
    "            logical_position = [r, c]\n",
    "            type = 'col'\n",
    "\n",
    "        return logical_position, type\n",
    "\n",
    "    def pointScored(self):\n",
    "        self.pointsScored = True\n",
    "\n",
    "    def mark_box(self):\n",
    "        boxes = np.argwhere(self.board_status == -4)\n",
    "        for box in boxes:\n",
    "            if tuple(box) not in [tuple(b) for b in self.already_marked_boxes]:\n",
    "                self.already_marked_boxes.append(list(box))\n",
    "                color = player1_color_light\n",
    "                self.shade_box(box, color)\n",
    "\n",
    "        boxes = np.argwhere(self.board_status == 4)\n",
    "        for box in boxes:\n",
    "            if tuple(box) not in [tuple(b) for b in self.already_marked_boxes]:\n",
    "                self.already_marked_boxes.append(list(box))\n",
    "                color = player2_color_light\n",
    "                self.shade_box(box, color)\n",
    "\n",
    "    def get_game_state_from_gui(self):\n",
    "        \"\"\"Helper method to convert GUI state to GameState object.\"\"\"\n",
    "        return GameState(\n",
    "            board_status=self.board_status.copy(),\n",
    "            row_status=self.row_status.copy(),\n",
    "            col_status=self.col_status.copy(),\n",
    "            player1_turn=self.player1_turn\n",
    "        )\n",
    "\n",
    "    def is_ai_turn(self):\n",
    "        return (not self.ai_agent.isPlayer1 and not self.player1_turn) or \\\n",
    "               (self.ai_agent.isPlayer1 and self.player1_turn)\n",
    "\n",
    "    def ai_move_if_needed(self):\n",
    "        if self.reset_board or not self.ai_mode or not self.is_ai_turn():\n",
    "            return\n",
    "\n",
    "        while True:\n",
    "            if self.is_gameover():\n",
    "                break\n",
    "\n",
    "            state = GameState(\n",
    "                board_status=self.board_status.copy(),\n",
    "                row_status=self.row_status.copy(),\n",
    "                col_status=self.col_status.copy(),\n",
    "                player1_turn=self.player1_turn\n",
    "            )\n",
    "\n",
    "            move_type, pos, _ = self.ai_agent.choose_move(state, max_depth=self.ai_max_depth)\n",
    "            if move_type is None:\n",
    "                break\n",
    "\n",
    "            self.update_board(move_type, pos)\n",
    "            self.make_edge(move_type, pos)\n",
    "            self.mark_box()\n",
    "            self.refresh_board()\n",
    "\n",
    "            if not self.pointsScored:\n",
    "                self.player1_turn = not self.player1_turn\n",
    "\n",
    "            self.pointsScored = False\n",
    "\n",
    "            if self.is_gameover():\n",
    "                self.display_gameover()\n",
    "                break\n",
    "\n",
    "            if not self.is_ai_turn():\n",
    "                self.display_turn_text()\n",
    "                break\n",
    "\n",
    "    def update_board(self, type, logical_position):\n",
    "        r = logical_position[0]\n",
    "        c = logical_position[1]\n",
    "        val = 1\n",
    "        playerModifier = -1 if self.player1_turn else 1\n",
    "\n",
    "        if c < (number_of_dots-1) and r < (number_of_dots-1):\n",
    "            self.board_status[c][r] = (abs(self.board_status[c][r]) + val) * playerModifier\n",
    "            if abs(self.board_status[c][r]) == 4:\n",
    "                self.pointScored()\n",
    "\n",
    "        if type == 'row':\n",
    "            self.row_status[c][r] = 1\n",
    "            if c >= 1:\n",
    "                self.board_status[c-1][r] = (abs(self.board_status[c-1][r]) + val) * playerModifier\n",
    "                if abs(self.board_status[c-1][r]) == 4:\n",
    "                    self.pointScored()\n",
    "\n",
    "        elif type == 'col':\n",
    "            self.col_status[c][r] = 1\n",
    "            if r >= 1:\n",
    "                self.board_status[c][r-1] = (abs(self.board_status[c][r-1]) + val) * playerModifier\n",
    "                if abs(self.board_status[c][r-1]) == 4:\n",
    "                    self.pointScored()\n",
    "\n",
    "    def is_gameover(self):\n",
    "        return (self.row_status == 1).all() and (self.col_status == 1).all()\n",
    "\n",
    "    def make_edge(self, type, logical_position):\n",
    "        if type == 'row':\n",
    "            start_x = distance_between_dots/2 + logical_position[0]*distance_between_dots\n",
    "            end_x = start_x+distance_between_dots\n",
    "            start_y = distance_between_dots/2 + logical_position[1]*distance_between_dots\n",
    "            end_y = start_y\n",
    "        elif type == 'col':\n",
    "            start_y = distance_between_dots / 2 + logical_position[1] * distance_between_dots\n",
    "            end_y = start_y + distance_between_dots\n",
    "            start_x = distance_between_dots / 2 + logical_position[0] * distance_between_dots\n",
    "            end_x = start_x\n",
    "\n",
    "        if self.player1_turn:\n",
    "            color = player1_color\n",
    "        else:\n",
    "            color = player2_color\n",
    "        self.canvas.create_line(start_x, start_y, end_x, end_y, fill=color, width=edge_width)\n",
    "\n",
    "    def display_gameover(self):\n",
    "        player1_score = len(np.argwhere(self.board_status == -4))\n",
    "        player2_score = len(np.argwhere(self.board_status == 4))\n",
    "\n",
    "        if player1_score > player2_score:\n",
    "            text = 'Winner: Player 1 '\n",
    "            color = player1_color\n",
    "        elif player2_score > player1_score:\n",
    "            text = 'Winner: Player 2 '\n",
    "            color = player2_color\n",
    "        else:\n",
    "            text = 'Its a tie'\n",
    "            color = 'gray'\n",
    "\n",
    "        self.canvas.delete(\"all\")\n",
    "        self.canvas.create_text(size_of_board / 2, size_of_board / 3, font=\"cmr 60 bold\", fill=color, text=text)\n",
    "\n",
    "        score_text = 'Scores \\n'\n",
    "        self.canvas.create_text(size_of_board / 2, 5 * size_of_board / 8, font=\"cmr 40 bold\", fill=text_color,\n",
    "                                text=score_text)\n",
    "\n",
    "        score_text = 'Player 1 : ' + str(player1_score) + '\\n'\n",
    "        score_text += 'Player 2 : ' + str(player2_score) + '\\n'\n",
    "        self.canvas.create_text(size_of_board / 2, 3 * size_of_board / 4, font=\"cmr 30 bold\", fill=text_color,\n",
    "                                text=score_text)\n",
    "        self.reset_board = True\n",
    "\n",
    "        score_text = 'Click to play again \\n'\n",
    "        self.canvas.create_text(size_of_board / 2, 15 * size_of_board / 16, font=\"cmr 20 bold\", fill=\"gray\",\n",
    "                                text=score_text)\n",
    "\n",
    "    def refresh_board(self):\n",
    "        for i in range(number_of_dots):\n",
    "            x = i*distance_between_dots+distance_between_dots/2\n",
    "            self.canvas.create_line(x, distance_between_dots/2, x,\n",
    "                                    size_of_board-distance_between_dots/2,\n",
    "                                    fill='gray', dash = (2, 2))\n",
    "            self.canvas.create_line(distance_between_dots/2, x,\n",
    "                                    size_of_board-distance_between_dots/2, x,\n",
    "                                    fill='gray', dash=(2, 2))\n",
    "\n",
    "        for i in range(number_of_dots):\n",
    "            for j in range(number_of_dots):\n",
    "                start_x = i*distance_between_dots+distance_between_dots/2\n",
    "                end_x = j*distance_between_dots+distance_between_dots/2\n",
    "                self.canvas.create_oval(start_x-dot_width/2, end_x-dot_width/2, start_x+dot_width/2,\n",
    "                                        end_x+dot_width/2, fill=dot_color,\n",
    "                                        outline=dot_color)\n",
    "\n",
    "    def display_turn_text(self):\n",
    "        text = 'Next turn: '\n",
    "        if self.player1_turn:\n",
    "            text += 'Player1'\n",
    "            color = player1_color\n",
    "        else:\n",
    "            text += 'Player2'\n",
    "            color = player2_color\n",
    "\n",
    "        self.canvas.delete(self.turntext_handle)\n",
    "        self.turntext_handle = self.canvas.create_text(size_of_board - 5*len(text),\n",
    "                                                       size_of_board-distance_between_dots/8,\n",
    "                                                       font=\"cmr 15 bold\", text=text, fill=color)\n",
    "\n",
    "    def shade_box(self, box, color):\n",
    "        start_x = distance_between_dots / 2 + box[1] * distance_between_dots + edge_width/2\n",
    "        start_y = distance_between_dots / 2 + box[0] * distance_between_dots + edge_width/2\n",
    "        end_x = start_x + distance_between_dots - edge_width\n",
    "        end_y = start_y + distance_between_dots - edge_width\n",
    "        self.canvas.create_rectangle(start_x, start_y, end_x, end_y, fill=color, outline='')\n",
    "\n",
    "    def click(self, event):\n",
    "        if not self.reset_board:\n",
    "            grid_position = [event.x, event.y]\n",
    "            logical_positon, valid_input = self.convert_grid_to_logical_position(grid_position)\n",
    "            if valid_input and not self.is_grid_occupied(logical_positon, valid_input):\n",
    "                self.update_board(valid_input, logical_positon)\n",
    "                self.make_edge(valid_input, logical_positon)\n",
    "                self.mark_box()\n",
    "                self.refresh_board()\n",
    "\n",
    "                if not self.pointsScored:\n",
    "                    self.player1_turn = not self.player1_turn\n",
    "\n",
    "                self.pointsScored = False\n",
    "\n",
    "                if self.is_gameover():\n",
    "                    self.display_gameover()\n",
    "                else:\n",
    "                    self.display_turn_text()\n",
    "                    if self.ai_mode:\n",
    "                        self.ai_move_if_needed()\n",
    "        else:\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.play_again()\n",
    "            self.reset_board = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7a247b",
   "metadata": {},
   "source": [
    "## Run the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c71aadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the game\n",
    "game_instance = Dots_and_Boxes()\n",
    "game_instance.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7499a39f",
   "metadata": {},
   "source": [
    "## سوالات\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68aeb3b",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.95; font-family: Tahoma;\">\n",
    "\n",
    "<h3 style=\"margin-top: 20px;\">سؤال ۱:</h3>\n",
    "\n",
    "\n",
    "<div style=\"display: flex; gap: 15px; margin-bottom: 25px;\">\n",
    "  <div style=\"flex: 1; text-align: center; padding: 10px; border-radius: 6px;\">\n",
    "    <h3 style=\"margin-top: 0;\">Board Size 3×3</h3>\n",
    "    <img src=\"dataframe_3*3.png\" width=\"100%\" style=\"border-radius: 4px;\">\n",
    "  </div>\n",
    "  <div style=\"flex: 1; text-align: center; padding: 10px; border-radius: 6px;\">\n",
    "    <h3 style=\"margin-top: 0;\">Board Size 4×4</h3>\n",
    "    <img src=\"dataframe_4*4.png\" width=\"100%\" style=\"border-radius: 4px;\">\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "<p>\n",
    "در عمق‌های کم مانند ۲، الگوریتم تنها بخشی از حالات پیشِ‌رو را بررسی می‌کند و به همین دلیل کیفیت تصمیم‌گیری محدود می‌ماند.  \n",
    "با افزایش عمق به مقدار ۴، مشاهده می‌شود که الگوریتم دید کامل‌تری نسبت به مسیر بازی پیدا می‌کند و در نتیجه دقت تصمیم‌گیری و نرخ پیروزی به‌طور محسوسی افزایش می‌یابد. همچنین با افزایش عمق دقت و winrate هم بیشتر می شود اما تعداد نود های دیده شده و سربار محاسباتی نیز به طور نمایی و شدید به ویژه بدون استفاده از purning رشد می کند\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">تأثیر عمق بر هزینهٔ محاسباتی</h4>\n",
    "\n",
    "<p>\n",
    "با افزایش عمق، تعداد نودهای بررسی‌شده به‌صورت نمایی رشد می‌کند.  \n",
    "در آزمایش‌ها مشاهده شد که در عمق ۶ (بدون Pruning) برخی حالت‌ها تا صدها هزار نود را شامل شده‌اند و زمان اجرا به چندین ثانیه رسیده است.  \n",
    "از آن‌جا که این افزایش شدید در زمان اجرا با بهبود کافی در دقت همراه نیست، استفاده از عمق‌های خیلی زیاد مقرون‌به‌صرفه محسوب نمی‌شود.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">نقش Pruning</h4>\n",
    "\n",
    "<ul>\n",
    "    <li>تعداد نودهای بررسی‌شده به‌طور چشمگیری کاهش پیدا می‌کند،</li>\n",
    "    <li>زمان اجرا کوتاه‌تر می‌شود،</li>\n",
    "    <li>در عین حال کیفیت تصمیم‌گیری تقریبا حفظ می‌شود.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "این کاهش بار محاسباتی به الگوریتم اجازه می‌دهد در عمق‌های مفید مانند ۴ عملکرد بسیار بهتری داشته باشد.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">انتخاب عمق بهینه</h4>\n",
    "\n",
    "<p>\n",
    "با توجه به نتایج، عمق ۴ بهترین نقطهٔ تعادل بین دقت تصمیم‌گیری و هزینهٔ محاسباتی است. در این عمق:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li>نرخ پیروزی نسبت به عمق ۲ بهبود قابل توجهی دارد،</li>\n",
    "    <li>زمان اجرا همچنان در سطح منطقی و قابل استفاده است،</li>\n",
    "    <li>هزینهٔ محاسباتی به‌مراتب کمتر از عمق ۶ است.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "در نتیجه، برای رسیدن به عملکرد پایدار و کارآمد، استفاده از عمق ۴ (ترجیحاً همراه با Pruning) انتخاب بهینه محسوب می‌شود.\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dfdff3",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-family: Tahoma;\">\n",
    "\n",
    "<h3 style=\"margin-top: 20px;\">سؤال ۲:</h3>\n",
    "\n",
    "<p>\n",
    "در الگوریتم Minimax همراه با هرس آلفا–بتا، ترتیب بررسی حرکات نقش بسیار مهمی در میزان کارایی هرس دارد.  \n",
    "هرچه حرکات بهتر زودتر بررسی شوند، احتمال بسته شدن شاخه‌های بی‌فایده بیشتر می‌شود و بخشی از درخت تصمیم هرگز پردازش نمی‌گردد.  \n",
    "بنابراین الگوریتم زمانی بیشترین کارایی را دارد که اولین حرکت‌های بررسی‌شده، گزینه‌های قوی‌تری باشند و مقدار آلفا یا بتا را سریع‌تر به‌روزرسانی کنند.  \n",
    "در این حالت، مقادیر حدی زودتر به دست می‌آیند و شاخه‌هایی که نتیجهٔ آن‌ها قطعاً نامطلوب است، سریع‌تر کنار گذاشته می‌شوند.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "```python\n",
    "def _order_moves(state: GameState, moves: List[Tuple[str, List[int]]]) -> List[Tuple[str, List[int]]]:\n",
    "    completing_moves = []\n",
    "    safe_moves = []\n",
    "    risky_moves = []\n",
    "\n",
    "    for move_type, pos in moves:\n",
    "        test_state = state.clone()\n",
    "        scored = test_state.apply_move(move_type, pos)\n",
    "\n",
    "        if scored:\n",
    "            completing_moves.append((move_type, pos))\n",
    "        else:\n",
    "            before = int(np.count_nonzero(np.abs(state.board_status) == 3))\n",
    "            after  = int(np.count_nonzero(np.abs(test_state.board_status) == 3))\n",
    "\n",
    "            if after > before:\n",
    "                risky_moves.append((move_type, pos))\n",
    "            else:\n",
    "                safe_moves.append((move_type, pos))\n",
    "\n",
    "    return completing_moves + safe_moves + risky_moves\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-family: Tahoma;\">\n",
    "<h4 style=\"margin-top: 18px;\">تحلیل کد _order_moves</h4>\n",
    "\n",
    "<p>\n",
    "این تابع برای ارزیابی اثر هر حرکت، ابتدا یک نسخهٔ کپی از وضعیت بازی می‌سازد و حرکت را روی آن تست می‌کند تا بدون تغییر حالت اصلی بتوان رفتار آن را تشخیص داد.\n",
    "حرکت‌هایی که منجر به تکمیل جعبه می‌شوند در اولویت اول قرار می‌گیرند، چون این حرکات مستقیم امتیاز تولید می‌کنند و معمولاً بیشترین تأثیر را در نتیجهٔ بازی دارند. پس از آن، حرکت‌های ایمن قرار داده می‌شوند؛ یعنی حرکت‌هایی که وضعیت خطرناک برای خانه‌ها ایجاد نمی‌کنند و در مجموع ریسک پایینی دارند. در نهایت، حرکت‌هایی که باعث نزدیک شدن یک خانه به تکمیل‌شدن می‌شوند و احتمال امتیازدهی حریف را بالا می‌برند، در دستهٔ حرکات پرریسک قرار می‌گیرند.\n",
    "این ترتیب‌بندی باعث می‌شود Minimax ابتدا حرکات مهم‌تر و کم‌خطرتر را بررسی کند و مقدار آلفا یا بتا سریع‌تر تنظیم شود. در نتیجه بخش زیادی از شاخه‌های بی‌اثر یا نامطلوب زودتر حذف می‌شوند و حجم جستجو کاهش پیدا می‌کند.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">نسخه بهبود یافته پیشنهادی</h4>\n",
    "\n",
    "<p>\n",
    "می توانیم از ایده ای که برای هیوریستیک دوم داشتیم استفاده کنیم یعنی فقط به اثر فوری حرکت نگاه نکنیم، بلکه ببینیم این حرکت در چند قدم بعد چه وضعیتی ایجاد می‌کند. بعضی حرکت‌ها ممکن است در لحظه امتیاز ندهند یا حتی معمولی به‌نظر برسند، اما در ادامه تعداد حرکت‌های امن را بیشتر می‌کنند یا فضای بازی را به نفع ما تغییر می‌دهند. برعکس، بعضی حرکت‌ها در ظاهر بی‌خطرند اما در آینده موقعیت‌های ریسکی زیادی ایجاد می‌کنند.\n",
    "برای این کار کافی است بعد از تست هر حرکت، وضعیت جدید را بررسی کنیم و حرکت‌های ممکن در آن حالت را به‌طور سطحی امتیازدهی کنیم. اگر حرکت آینده را به سمت موقعیت‌های امن‌تر ببرد امتیاز مثبت می‌گیرد و اگر تعداد موقعیت‌های خطرناک بیشتر شود امتیاز منفی اضافه می‌شود. این امتیاز به امتیاز اصلی حرکت اضافه می‌شود و ترتیب نهایی را دقیق‌تر می‌کند.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8242c3d",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-family: Tahoma;\">\n",
    "\n",
    "<h3 style=\"margin-top: 20px;\">سؤال ۳:</h3>\n",
    "\n",
    "<p>\n",
    "Branching Factor یعنی تعداد حرکت‌هایی که در هر وضعیت از بازی می‌توان انجام داد.  \n",
    "درواقع نشان می‌دهد از یک حالت، چند مسیر جدید درخت تصمیم باز می‌شود. هرچه این عدد بیشتر باشد، درخت تصمیم بزرگ‌تر می‌شود و Minimax باید حالات بیشتری را بررسی کند.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "در بازی Dots and Boxes این مقدار در ابتدای بازی بیشترین مقدار خودش را دارد، چون تقریباً همهٔ خطوط خالی هستند.  \n",
    "مثلاً در صفحهٔ 3×3 (با ۹ نقطه) در مجموع ۱۲ خط ممکن داریم؛ در حرکت اول هر ۱۲ خط قابل انتخاب است.  \n",
    "اما با جلو رفتن بازی و کشیده شدن خطوط، تعداد حرکت‌های مجاز کم می‌شود و ممکن است در انتهای بازی فقط ۲ یا ۳ حرکت باقی بماند.\n",
    "این کاهش تدریجی باعث می‌شود Minimax در شروع بازی جستجوی سنگین‌تری داشته باشد،  \n",
    "ولی در مراحل پایانی که Branching Factor کوچک‌تر است، بتواند عمق بیشتری را با هزینهٔ محاسباتی کمتر بررسی کند.  \n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c37c3c",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-family: Tahoma;\">\n",
    "\n",
    "<h3 style=\"margin-top: 20px;\"> سؤال ۴</h3>\n",
    "\n",
    "<p>\n",
    " هرس آلفا-بتا تکنیکی برای بهینه‌سازی الگوریتم Minimax است. هدف اصلی این است که بدون بررسی تمام شاخه‌های درخت بازی، دقیقاً به همان نتیجه‌ای برسیم که الگوریتم کامل Minimax می‌رسد. این یعنی هیچ حرکت بهینه‌ای از دست نمی‌رود، بلکه فقط مسیرهایی که \"مطمئن هستیم نتیجه نهایی را تغییر نمی‌دهند\" حذف می‌شوند.به این صورت کار می کند که ما دو متغیر را در طول جستجو در درخت همراه خود نگه می‌داریم:آلفا یعنی بهترین (بالاترین) امتیازی که بازیکن Maximizer تا این لحظه در مسیر جستجو تضمین کرده است. (مقدار اولیه: منفی بی نهیات)و بتا یعنی بهترین (پایین‌ترین) امتیازی که بازیکن Minimizer (حریف) تا این لحظه در مسیر جستجو تضمین کرده است. (مقدار اولیه: مثبت بی نهایت) شرط هرس کردن:اگر در یک نود متوجه شویم که بتا کوچتر مساوی آلفا شده جستجو در آن شاخه را متوقف می‌کنیم چون این یعنی حریف مسیری پیدا کرده که امتیازش برای ما کمتر یا مساوی مسیری است که قبلاً پیدا کرده بودیم. پس حریف قطعاً ما را به سمت آن امتیاز پایین هل می‌دهد. چون ما قبلاً راه بهتری (آلفا) سراغ داشتیم، هرگز وارد این شاخه نمی‌شویم. پس دیدن بقیه زیرشاخه‌های آن اتلاف وقت است.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">مثال برای یک بورد ۲*۲</h4>\n",
    "\n",
    "<div style=\"direction:ltr; text-align:left; margin: 15px 0;\">\n",
    "<pre><code>\n",
    " Node d=1 | max=False | α=-inf | β=inf\n",
    "    Try ('row', [0, 1])\n",
    "    Node d=2 | max=True | α=-inf | β=inf\n",
    "       Try ('col', [0, 0])\n",
    "       Node d=3 | max=True | α=-inf | β=inf\n",
    "          child=50 | α:-inf→50 | β=inf\n",
    "       child=50 | α=-inf | β:inf→50\n",
    "    Try ('col', [0, 0])\n",
    "    Node d=2 | max=True | α=-inf | β=50\n",
    "       Try ('row', [0, 1])\n",
    "       Node d=3 | max=True | α=-inf | β=50\n",
    "          child=50 | α:-inf→50 | β=50\n",
    "       ✂ Pruned because β(50) ≤ α(50)\n",
    "       child=50 | α=-inf | β:50→50\n",
    " Node d=1 | max=False | α=50 | β=inf\n",
    "</code></pre>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "در این قسمت MIN یک فرزند را بررسی می‌کند و مقدار ۵۰ به‌دست می‌آورد.  \n",
    "بنابراین مقدار <b>بتا از ∞ به ۵۰</b> کاهش پیدا می‌کند.  \n",
    "اما آلفا هم‌اکنون <b>۵۰</b> است؛ یعنی MIN هیچ شانسی ندارد که مقدار کوچک‌تر از ۵۰ پیدا کند.  \n",
    "پس ادامهٔ این شاخه کاملاً بی‌فایده است و الگوریتم با شرط <b>β ≤ α</b> آن را قطع می‌کند.\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec773605",
   "metadata": {},
   "source": [
    "<div dir=\"rtl\" style=\"text-align: justify; line-height: 1.9; font-family: Tahoma;\">\n",
    "\n",
    "<h3 style=\"margin-top: 20px;\">سؤال ۵:</h3>\n",
    "\n",
    "<p>\n",
    "وقتی حریف حرکاتش را کاملاً تصادفی انتخاب می‌کند، استفاده از Minimax مخصوصاً در عمق‌های بالا عملاً به‌صرفه نیست.  \n",
    "Minimax برای هر حالت حریف بدترین حالت ممکن را در نظر می‌گیرد و یک جستجوی کامل روی درخت انجام می‌دهد.  \n",
    "اما اگر حریف اصلاً استراتژیک رفتار نمی‌کند و به شکل تصادفی بازی می‌کند، هزینهٔ محاسباتی Minimax بیش از چیزی است که واقعاً نیاز است.\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "در چنین شرایطی، الگوریتمی مانند  \n",
    "<b>Monte Carlo Tree Search (MCTS)</b>  \n",
    "عملکرد بسیار بهتری دارد، چون به‌جای جستجوی کامل و عمیق، با نمونه‌برداری تصادفی مسیرهای مختلف را امتحان می‌کند و میانگین نتایج را مبنای تصمیم‌گیری قرار می‌دهد.\n",
    "بنابر این اگر حریف غیر قابل پیشبینی باشد یا فضای حالت خیلی بزرگ باشد این الگوریتم بسیار کارآمد است\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">نقش UCB و نحوهٔ کار MCTS</h4>\n",
    "\n",
    "<p>\n",
    "MCTS برای انتخاب حرکت از معیار  \n",
    "<b>Upper Confidence Bound – UCB</b>  \n",
    "استفاده می‌کند. ایدهٔ اصلی UCB این است که بین دو چیز تعادل برقرار کند:\n",
    "</p>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Exploration</b>: امتحان حرکت‌هایی که کمتر بررسی شده‌اند،</li>\n",
    "    <li><b>Exploitation</b>: انتخاب حرکت‌هایی که تا اینجا نتیجهٔ خوبی داده‌اند.</li>\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "UCB برای هر حرکت یک امتیاز می‌سازد که در آن هم «میانگین موفقیت حرکت» و هم «تعداد دفعات امتحان‌شدن آن» در نظر گرفته می‌شود.  \n",
    "به همین دلیل، MCTS بدون اینکه درخت را کامل بگردد، به مرور زمان بهترین حرکت‌ها را پیدا می‌کند و شاخه‌هایی که امید کمی دارند کمتر مورد بررسی قرار می‌گیرند.\n",
    "</p>\n",
    "\n",
    "<h4 style=\"margin-top: 18px;\">مزیت MCTS در برابر Minimax برای حریف تصادفی</h4>\n",
    "\n",
    "<p>\n",
    "وقتی حریف تصادفی است، Minimax برای هر حرکت یک درخت عمیق می‌سازد؛ کاری که کاملاً غیرضروری است.  \n",
    "اما MCTS فقط با شبیه‌سازی‌های زیاد متوجه می‌شود که بسیاری از شاخه‌ها ارزش دنبال‌کردن ندارند و تمرکزش را روی مسیرهای امیدبخش می‌گذارد.  \n",
    " به همین دلیل در سناریوهای حریف تصادفی MCTS سریع‌تر بوده و نتیجه بهتری می دهد\n",
    "</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
